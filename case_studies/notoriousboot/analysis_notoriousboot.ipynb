{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<br>\n",
    "Brief explanation on our Booter database analysis methodology: <br>\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of: notoriousboot\n",
    "#### File originally retrieved from: http://pastebin.com/L0miVqSB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Libraries that I use to analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "from IPython.display import display,clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<br>\n",
    "STEP 0: Reading an input Booter database file<br>\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dumpfile='notoriousboot.sql'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<br>\n",
    "STEP 1: Adaptation to our Booter database schema<br>\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the first 'N' (100) lines of the input Booter database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- --------------------------------------------------------------------------------\n",
      "--\n",
      "-- phpMyAdmin SQL Dump\n",
      "-- version 4.0.8\n",
      "-- http://www.phpmyadmin.net\n",
      "--\n",
      "-- Host: localhost\n",
      "-- Generation Time: Feb 08, 2014 at 10:02 PM\n",
      "-- Server version: 5.5.35-cll\n",
      "-- PHP Version: 5.3.17\n",
      "\n",
      "SET SQL_MODE = \"NO_AUTO_VALUE_ON_ZERO\";\n",
      "SET time_zone = \"+00:00\";\n",
      "\n",
      "\n",
      "/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n",
      "/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n",
      "/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n",
      "/*!40101 SET NAMES utf8 */;\n",
      "\n",
      "--\n",
      "-- Database: `notoriou_ceg`\n",
      "--\n",
      "\n",
      "-- --------------------------------------------------------\n",
      "\n",
      "--\n",
      "-- Table structure for table `api`\n",
      "--\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS `api` (\n",
      "`id` int(11) NOT NULL AUTO_INCREMENT,\n",
      "`api` varchar(1024) NOT NULL,\n",
      "PRIMARY KEY (`id`)\n",
      ") ENGINE=MyISAM  DEFAULT CHARSET=latin1 AUTO_INCREMENT=60 ;\n",
      "\n",
      "--\n",
      "-- Dumping data for table `api`\n",
      "--\n",
      "\n",
      "INSERT INTO `api` (`id`, `api`) VALUES\n",
      "(59, 'http://unlimitedapi.com/apisystem2/doAPI.php?key=abased101&host=[host]&port=[port]&time=[time]&method=[method]');\n",
      "\n",
      "-- --------------------------------------------------------\n",
      "\n",
      "--\n",
      "-- Table structure for table `blacklist`\n",
      "--\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS `blacklist` (\n",
      "`ID` int(11) NOT NULL AUTO_INCREMENT,\n",
      "`IP` varchar(15) NOT NULL,\n",
      "`note` text NOT NULL,\n",
      "PRIMARY KEY (`ID`)\n",
      ") ENGINE=MyISAM  DEFAULT CHARSET=latin1 AUTO_INCREMENT=26 ;\n",
      "\n",
      "--\n",
      "-- Dumping data for table `blacklist`\n",
      "--\n",
      "\n",
      "INSERT INTO `blacklist` (`ID`, `IP`, `note`) VALUES\n",
      "(22, '5.66.226.81', 'Tasha <3'),\n",
      "(18, '86.169.119.130', 'Aimee'),\n",
      "(25, '31.54.51.54', 'Tiffany'),\n",
      "(23, '71.28.79.79', 'Ashes');\n",
      "\n",
      "-- --------------------------------------------------------\n",
      "\n",
      "--\n",
      "-- Table structure for table `fe`\n",
      "--\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS `fe` (\n",
      "`ID` int(11) NOT NULL AUTO_INCREMENT,\n",
      "`userID` int(11) NOT NULL,\n",
      "`type` varchar(1) NOT NULL,\n",
      "`ip` varchar(15) NOT NULL,\n",
      "`note` text NOT NULL,\n",
      "PRIMARY KEY (`ID`)\n",
      ") ENGINE=MyISAM  DEFAULT CHARSET=latin1 AUTO_INCREMENT=11 ;\n",
      "\n",
      "--\n",
      "-- Dumping data for table `fe`\n",
      "--\n",
      "\n",
      "INSERT INTO `fe` (`ID`, `userID`, `type`, `ip`, `note`) VALUES\n",
      "(1, 19, 'f', '82.3.108.3', 'ezaM'),\n",
      "(5, 41, 'f', '108.87.71.77', 'Tyler/Kue'),\n",
      "(7, 1, 'e', '88.6.67.115', 'Primark'),\n",
      "(8, 1, 'e', '82.23.42.77', 'Shannon'),\n",
      "(9, 1, 'e', '5.198.9.44', 'Bongazm'),\n",
      "(10, 122, 'e', '189.15.76.247', 'Website Stealer');\n",
      "\n",
      "-- --------------------------------------------------------\n",
      "\n",
      "--\n",
      "-- Table structure for table `gateway`\n",
      "--\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS `gateway` (\n"
     ]
    }
   ],
   "source": [
    "lines_to_read=100\n",
    "\n",
    "with open(dumpfile) as myfile:\n",
    "    firstlines=myfile.readlines()[0:lines_to_read] #put here the interval you want\n",
    "    for x in firstlines:\n",
    "        print(x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Listing tables that have content inserted into the dump file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_tables_with_insert(dumpfile):\n",
    "    tables = []\n",
    "    with open(dumpfile, 'rb') as f:\n",
    "        for line in f:\n",
    "            line = line.decode(\"utf-8\").strip()\n",
    "            if line.lower().startswith('insert'):\n",
    "                table = re.findall(r'`(.*?)`', line)\n",
    "                tables.append(table[0])\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 api\n",
      "2 blacklist\n",
      "3 fe\n",
      "4 gateway\n",
      "5 iplogs\n",
      "6 logs\n",
      "7 logs\n",
      "8 news\n",
      "9 payments\n",
      "10 plans\n",
      "11 users\n"
     ]
    }
   ],
   "source": [
    "tables=enumerate(list_tables_with_insert(dumpfile))\n",
    "\n",
    "for i, item in tables:\n",
    "    print(i+1,item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the list above looks like? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>======================================================================\n",
    "If NOT well-formed SQL dump file then you must first do the following:\n",
    "======================================================================</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removing lines that are not part of the actual content to be analysed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting and naming tables and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>======================================================================\n",
    "Additional functions\n",
    "======================================================================</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Function to read tables from wel-formed SQL database dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For well formed SQL database dumps!\n",
    "def read_inserted_table(dumpfile, target_table):\n",
    "    sio = StringIO()\n",
    "    fast_forward = True\n",
    "    already_header = False\n",
    "    with open(dumpfile, 'rb') as f:\n",
    "        for line in f:\n",
    "            line = line.decode(\"utf-8\").strip()\n",
    "            line = re.sub(\"(?!(([^']*'){2})*[^']*$)\\)\", '',line) #Step0:remove any \")\" from the content of columns\n",
    "            if line.lower().startswith('insert') and target_table in line:\n",
    "                fast_forward = False\n",
    "                if already_header:\n",
    "                    continue\n",
    "            if fast_forward:\n",
    "                continue\n",
    "            \n",
    "            data = re.findall('\\([^\\)]*\\)', line) #Step1: get the content between parentesis (i.e., insert line)\n",
    "            try:\n",
    "                newline = data[0].strip('()') #Step2:remove parenthesis\n",
    "                newline=newline.replace('`','') #Step3: remove ` (usually in table names)\n",
    "                newline=re.sub(r'(?!(([^\\']*\\'){2})*[^\\']*$),','', newline) #Step4: remove commas from the content of columns\n",
    "                newline=newline.replace('\\'','') #Step5: remove single quotes\n",
    "                newline=newline.replace(', ', ',') #Step6: remove single spaces after comma (i.e., in the beginning of a column)\n",
    "                sio.write(newline)\n",
    "                sio.write(\"\\n\")\n",
    "            except IndexError:\n",
    "                pass\n",
    "            if line.endswith(';'):\n",
    "                fast_forward = True\n",
    "                already_header = True\n",
    "    sio.seek(0)\n",
    "    return sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Converter functions for formatting content of columns\n",
    "Attention, it is better to perform the conversion based on a series than a string (http://stackoverflow.com/questions/42462906/pandas-read-csv-converters-performance-issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tolowercase(series):\n",
    "    return series.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_singlequote(series):\n",
    "    return series.str.strip('\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp2datetime(series):\n",
    "    return  pd.to_datetime(series,unit='s',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetimestring2datetime(series):\n",
    "    return  pd.to_datetime(series, format='%d-%m-%Y %H:%M',errors='coerce')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetimeinvertedstring2datetime(series):\n",
    "    return pd.to_datetime(series, format='%Y-%m-%d %H:%M:%S',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetimeampm2datetime(series):\n",
    "    return  pd.to_datetime(series,format='%d-%m-%Y %I:%M:%S %p',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetimemdyampm2datetime(series):\n",
    "    return  pd.to_datetime(series, format='%m-%d-%Y %I:%M:%S %p',errors='coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_parenthesisandsemicolon(series):\n",
    "    return series.str.strip(');')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_insertintologs(series):\n",
    "    return int(series.str.strip('INSERT INTO `logs` VALUES ('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_tab(series):\n",
    "    return series.str.strip('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def friendsenemies_type(series):\n",
    "    return series.str.replace('f','friend').replace('e','enemy')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>======================================================================\n",
    "Adapting EACH existing table\n",
    "======================================================================</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Table: 'api'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>http://unlimitedapi.com/apisystem2/doAPI.php?k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                api\n",
       "0  59  http://unlimitedapi.com/apisystem2/doAPI.php?k..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='api'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile,tablename),delimiter=\",\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES\n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? NO\n",
    "    - This table looks like: \n",
    "    \n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type/converter: \n",
    "        o \n",
    "    - On the column name:\n",
    "        o \n",
    "    - Split columns:\n",
    "        o \n",
    "    - Add required columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Table: 'blacklist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>IP</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>5.66.226.81</td>\n",
       "      <td>Tasha &lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>86.169.119.130</td>\n",
       "      <td>Aimee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>31.54.51.54</td>\n",
       "      <td>Tiffany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>71.28.79.79</td>\n",
       "      <td>Ashes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              IP      note\n",
       "0  22     5.66.226.81  Tasha <3\n",
       "1  18  86.169.119.130     Aimee\n",
       "2  25     31.54.51.54   Tiffany\n",
       "3  23     71.28.79.79     Ashes"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='blacklist'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES\n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES\n",
    "    - This table looks like: blacklist\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o \n",
    "    - On the column name:\n",
    "        o ID -> id\n",
    "        o IP -> ip\n",
    "    - Add required columns:\n",
    "        o  \n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'blacklist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ip</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>5.66.226.81</td>\n",
       "      <td>Tasha &lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>86.169.119.130</td>\n",
       "      <td>Aimee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>31.54.51.54</td>\n",
       "      <td>Tiffany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>71.28.79.79</td>\n",
       "      <td>Ashes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              ip      note\n",
       "0  22     5.66.226.81  Tasha <3\n",
       "1  18  86.169.119.130     Aimee\n",
       "2  25     31.54.51.54   Tiffany\n",
       "3  23     71.28.79.79     Ashes"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_blacklist = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "\n",
    "# Changing column names\n",
    "df_blacklist.rename(inplace=True, columns = {'ID': 'id',\n",
    "                                            'IP':'ip'})\n",
    "\n",
    "# Adding missing columns (with \"\" [for future string] or np.nan [for future float])\n",
    "\n",
    "###Showing some lines after adapt the table\n",
    "df_blacklist.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Table: 'fe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>userID</th>\n",
       "      <th>type</th>\n",
       "      <th>ip</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>f</td>\n",
       "      <td>82.3.108.3</td>\n",
       "      <td>ezaM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>f</td>\n",
       "      <td>108.87.71.77</td>\n",
       "      <td>Tyler/Kue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>88.6.67.115</td>\n",
       "      <td>Primark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>82.23.42.77</td>\n",
       "      <td>Shannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>5.198.9.44</td>\n",
       "      <td>Bongazm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>e</td>\n",
       "      <td>189.15.76.247</td>\n",
       "      <td>Website Stealer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  userID type             ip             note\n",
       "0   1      19    f     82.3.108.3             ezaM\n",
       "1   5      41    f   108.87.71.77        Tyler/Kue\n",
       "2   7       1    e    88.6.67.115          Primark\n",
       "3   8       1    e    82.23.42.77          Shannon\n",
       "4   9       1    e     5.198.9.44          Bongazm\n",
       "5  10     122    e  189.15.76.247  Website Stealer"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='fe'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES\n",
    "    - This table looks like: friendsenemies\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o fe -> friendsenemies\n",
    "    - On the column type: \n",
    "        o type -> friendsenemies_type() \n",
    "    - On the column name:\n",
    "        o ID -> id\n",
    "        o userID -> userid\n",
    "    - Add required columns:\n",
    "        o \n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'fe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userid</th>\n",
       "      <th>type</th>\n",
       "      <th>ip</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>friend</td>\n",
       "      <td>82.3.108.3</td>\n",
       "      <td>ezaM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>friend</td>\n",
       "      <td>108.87.71.77</td>\n",
       "      <td>Tyler/Kue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>enemy</td>\n",
       "      <td>88.6.67.115</td>\n",
       "      <td>Primark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>enemy</td>\n",
       "      <td>82.23.42.77</td>\n",
       "      <td>Shannon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>enemy</td>\n",
       "      <td>5.198.9.44</td>\n",
       "      <td>Bongazm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>enemy</td>\n",
       "      <td>189.15.76.247</td>\n",
       "      <td>Website Stealer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  userid    type             ip             note\n",
       "0   1      19  friend     82.3.108.3             ezaM\n",
       "1   5      41  friend   108.87.71.77        Tyler/Kue\n",
       "2   7       1   enemy    88.6.67.115          Primark\n",
       "3   8       1   enemy    82.23.42.77          Shannon\n",
       "4   9       1   enemy     5.198.9.44          Bongazm\n",
       "5  10     122   enemy  189.15.76.247  Website Stealer"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_friendenemies = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "df_friendenemies['type']=friendsenemies_type(df_friendenemies['type'])\n",
    "\n",
    "# Changing column names\n",
    "df_friendenemies.rename(inplace=True, columns = {'ID': 'id',\n",
    "                                            'userID':'userid'})\n",
    "\n",
    "# Adding missing columns (with \"\" [for future string] or np.nan [for future float])\n",
    "\n",
    "###Showing some lines after adapt the table\n",
    "df_friendenemies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Table: 'gateway'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abased@live.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             email\n",
       "0  abased@live.com"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='gateway'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES\n",
    "    - This table looks like: gateways\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o gateway -> gateways\n",
    "    - On the column type: \n",
    "        o  \n",
    "    - On the column name:\n",
    "        o \n",
    "    - Add required columns:\n",
    "        o \n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'gateway'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abased@live.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             email\n",
       "0  abased@live.com"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_gateways = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "\n",
    "# Changing column names\n",
    "\n",
    "# Showing some lines after adapt the tabledf_plans['maxboottime'] = np.nan\n",
    "\n",
    "# Showing some lines after adapt the table\n",
    "df_gateways.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Table: 'iplogs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>userID</th>\n",
       "      <th>logged</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>81.71.4.55</td>\n",
       "      <td>1388518491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>81.71.4.55</td>\n",
       "      <td>1388518469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>83.84.78.163</td>\n",
       "      <td>1388591989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2.125.14.193</td>\n",
       "      <td>1388785531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>195.240.183.161</td>\n",
       "      <td>1388619667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>98.15.189.166</td>\n",
       "      <td>1388785543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>2.125.14.193</td>\n",
       "      <td>1388785545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>178.167.243.117</td>\n",
       "      <td>1388785662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>109.158.251.94</td>\n",
       "      <td>1388787488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>109.158.251.94</td>\n",
       "      <td>1388787493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  userID           logged        date\n",
       "0   5      13       81.71.4.55  1388518491\n",
       "1   4      13       81.71.4.55  1388518469\n",
       "2   6      13     83.84.78.163  1388591989\n",
       "3  12      46     2.125.14.193  1388785531\n",
       "4   9      13  195.240.183.161  1388619667\n",
       "5  13      46    98.15.189.166  1388785543\n",
       "6  14      46     2.125.14.193  1388785545\n",
       "7  15      46  178.167.243.117  1388785662\n",
       "8  16      46   109.158.251.94  1388787488\n",
       "9  17      46   109.158.251.94  1388787493"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='iplogs'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES\n",
    "    - This table looks like: logins\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o date -> timestamp2datetime()\n",
    "    - On the column name:\n",
    "        o ID -> id\n",
    "        o userID -> userid\n",
    "        o logged -> userip\n",
    "    - Add required columns:\n",
    "        o username\n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'iplogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userid</th>\n",
       "      <th>userip</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>81.71.4.55</td>\n",
       "      <td>2013-12-31 19:34:51</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>81.71.4.55</td>\n",
       "      <td>2013-12-31 19:34:29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>83.84.78.163</td>\n",
       "      <td>2014-01-01 15:59:49</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2.125.14.193</td>\n",
       "      <td>2014-01-03 21:45:31</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>195.240.183.161</td>\n",
       "      <td>2014-01-01 23:41:07</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>98.15.189.166</td>\n",
       "      <td>2014-01-03 21:45:43</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>2.125.14.193</td>\n",
       "      <td>2014-01-03 21:45:45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>178.167.243.117</td>\n",
       "      <td>2014-01-03 21:47:42</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>109.158.251.94</td>\n",
       "      <td>2014-01-03 22:18:08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>109.158.251.94</td>\n",
       "      <td>2014-01-03 22:18:13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  userid           userip                date username\n",
       "0   5      13       81.71.4.55 2013-12-31 19:34:51         \n",
       "1   4      13       81.71.4.55 2013-12-31 19:34:29         \n",
       "2   6      13     83.84.78.163 2014-01-01 15:59:49         \n",
       "3  12      46     2.125.14.193 2014-01-03 21:45:31         \n",
       "4   9      13  195.240.183.161 2014-01-01 23:41:07         \n",
       "5  13      46    98.15.189.166 2014-01-03 21:45:43         \n",
       "6  14      46     2.125.14.193 2014-01-03 21:45:45         \n",
       "7  15      46  178.167.243.117 2014-01-03 21:47:42         \n",
       "8  16      46   109.158.251.94 2014-01-03 22:18:08         \n",
       "9  17      46   109.158.251.94 2014-01-03 22:18:13         "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_logins = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "df_logins['date'] = timestamp2datetime(df_logins['date']) \n",
    "\n",
    "# Changing names of columns\n",
    "df_logins.rename(inplace=True, columns = {'ID': 'id',\n",
    "                                         'userID': 'userid',\n",
    "                                         'logged':'userip'})\n",
    "\n",
    "# Creating empty columns (with \"\" [for future string] or np.nan [for future float])\n",
    "df_logins['username']=''\n",
    "\n",
    "\n",
    "# Showing some lines after adapt the table\n",
    "df_logins.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6. Table: 'logs'!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 14: expected 4 fields, saw 8\\nSkipping line 15: expected 4 fields, saw 8\\nSkipping line 16: expected 4 fields, saw 8\\nSkipping line 17: expected 4 fields, saw 8\\nSkipping line 18: expected 4 fields, saw 8\\nSkipping line 19: expected 4 fields, saw 8\\nSkipping line 20: expected 4 fields, saw 8\\nSkipping line 21: expected 4 fields, saw 8\\nSkipping line 22: expected 4 fields, saw 8\\nSkipping line 23: expected 4 fields, saw 8\\nSkipping line 24: expected 4 fields, saw 8\\nSkipping line 25: expected 4 fields, saw 8\\nSkipping line 26: expected 4 fields, saw 8\\nSkipping line 27: expected 4 fields, saw 8\\nSkipping line 28: expected 4 fields, saw 8\\nSkipping line 29: expected 4 fields, saw 8\\nSkipping line 30: expected 4 fields, saw 8\\nSkipping line 31: expected 4 fields, saw 8\\nSkipping line 32: expected 4 fields, saw 8\\nSkipping line 33: expected 4 fields, saw 8\\nSkipping line 34: expected 4 fields, saw 8\\nSkipping line 35: expected 4 fields, saw 8\\nSkipping line 36: expected 4 fields, saw 8\\nSkipping line 37: expected 4 fields, saw 8\\nSkipping line 38: expected 4 fields, saw 8\\nSkipping line 39: expected 4 fields, saw 8\\nSkipping line 40: expected 4 fields, saw 8\\nSkipping line 41: expected 4 fields, saw 8\\nSkipping line 42: expected 4 fields, saw 8\\nSkipping line 43: expected 4 fields, saw 8\\nSkipping line 44: expected 4 fields, saw 8\\nSkipping line 45: expected 4 fields, saw 8\\nSkipping line 46: expected 4 fields, saw 8\\nSkipping line 47: expected 4 fields, saw 8\\nSkipping line 48: expected 4 fields, saw 8\\nSkipping line 49: expected 4 fields, saw 8\\nSkipping line 50: expected 4 fields, saw 8\\nSkipping line 51: expected 4 fields, saw 8\\nSkipping line 52: expected 4 fields, saw 8\\nSkipping line 53: expected 4 fields, saw 8\\nSkipping line 54: expected 4 fields, saw 8\\nSkipping line 55: expected 4 fields, saw 8\\nSkipping line 56: expected 4 fields, saw 8\\nSkipping line 57: expected 4 fields, saw 8\\nSkipping line 58: expected 4 fields, saw 8\\nSkipping line 59: expected 4 fields, saw 8\\nSkipping line 60: expected 4 fields, saw 8\\nSkipping line 61: expected 4 fields, saw 8\\nSkipping line 62: expected 4 fields, saw 8\\nSkipping line 63: expected 4 fields, saw 8\\nSkipping line 64: expected 4 fields, saw 8\\nSkipping line 65: expected 4 fields, saw 8\\nSkipping line 66: expected 4 fields, saw 8\\nSkipping line 67: expected 4 fields, saw 8\\nSkipping line 68: expected 4 fields, saw 8\\nSkipping line 69: expected 4 fields, saw 8\\nSkipping line 70: expected 4 fields, saw 8\\nSkipping line 71: expected 4 fields, saw 8\\nSkipping line 72: expected 4 fields, saw 8\\nSkipping line 73: expected 4 fields, saw 8\\nSkipping line 74: expected 4 fields, saw 8\\nSkipping line 75: expected 4 fields, saw 8\\nSkipping line 76: expected 4 fields, saw 8\\nSkipping line 77: expected 4 fields, saw 8\\nSkipping line 78: expected 4 fields, saw 8\\nSkipping line 79: expected 4 fields, saw 8\\nSkipping line 80: expected 4 fields, saw 8\\nSkipping line 81: expected 4 fields, saw 8\\nSkipping line 82: expected 4 fields, saw 8\\nSkipping line 83: expected 4 fields, saw 8\\nSkipping line 84: expected 4 fields, saw 8\\nSkipping line 85: expected 4 fields, saw 8\\nSkipping line 86: expected 4 fields, saw 8\\nSkipping line 87: expected 4 fields, saw 8\\nSkipping line 88: expected 4 fields, saw 8\\nSkipping line 89: expected 4 fields, saw 8\\nSkipping line 90: expected 4 fields, saw 8\\nSkipping line 91: expected 4 fields, saw 8\\nSkipping line 92: expected 4 fields, saw 8\\nSkipping line 93: expected 4 fields, saw 8\\nSkipping line 94: expected 4 fields, saw 8\\nSkipping line 95: expected 4 fields, saw 8\\nSkipping line 96: expected 4 fields, saw 8\\nSkipping line 97: expected 4 fields, saw 8\\nSkipping line 98: expected 4 fields, saw 8\\nSkipping line 99: expected 4 fields, saw 8\\nSkipping line 100: expected 4 fields, saw 8\\nSkipping line 101: expected 4 fields, saw 8\\nSkipping line 102: expected 4 fields, saw 8\\nSkipping line 103: expected 4 fields, saw 8\\nSkipping line 104: expected 4 fields, saw 8\\nSkipping line 105: expected 4 fields, saw 8\\nSkipping line 106: expected 4 fields, saw 8\\nSkipping line 107: expected 4 fields, saw 8\\nSkipping line 108: expected 4 fields, saw 8\\nSkipping line 109: expected 4 fields, saw 8\\nSkipping line 110: expected 4 fields, saw 8\\nSkipping line 111: expected 4 fields, saw 8\\nSkipping line 112: expected 4 fields, saw 8\\nSkipping line 113: expected 4 fields, saw 8\\nSkipping line 114: expected 4 fields, saw 8\\nSkipping line 115: expected 4 fields, saw 8\\nSkipping line 116: expected 4 fields, saw 8\\nSkipping line 117: expected 4 fields, saw 8\\nSkipping line 118: expected 4 fields, saw 8\\nSkipping line 119: expected 4 fields, saw 8\\nSkipping line 120: expected 4 fields, saw 8\\nSkipping line 121: expected 4 fields, saw 8\\nSkipping line 122: expected 4 fields, saw 8\\nSkipping line 123: expected 4 fields, saw 8\\nSkipping line 124: expected 4 fields, saw 8\\nSkipping line 125: expected 4 fields, saw 8\\nSkipping line 126: expected 4 fields, saw 8\\nSkipping line 127: expected 4 fields, saw 8\\nSkipping line 128: expected 4 fields, saw 8\\nSkipping line 129: expected 4 fields, saw 8\\nSkipping line 130: expected 4 fields, saw 8\\nSkipping line 131: expected 4 fields, saw 8\\nSkipping line 132: expected 4 fields, saw 8\\nSkipping line 133: expected 4 fields, saw 8\\nSkipping line 134: expected 4 fields, saw 8\\nSkipping line 135: expected 4 fields, saw 8\\nSkipping line 136: expected 4 fields, saw 8\\nSkipping line 137: expected 4 fields, saw 8\\nSkipping line 138: expected 4 fields, saw 8\\nSkipping line 139: expected 4 fields, saw 8\\nSkipping line 140: expected 4 fields, saw 8\\nSkipping line 141: expected 4 fields, saw 8\\nSkipping line 142: expected 4 fields, saw 8\\nSkipping line 143: expected 4 fields, saw 8\\nSkipping line 144: expected 4 fields, saw 8\\nSkipping line 145: expected 4 fields, saw 8\\nSkipping line 146: expected 4 fields, saw 8\\nSkipping line 147: expected 4 fields, saw 8\\nSkipping line 148: expected 4 fields, saw 8\\nSkipping line 149: expected 4 fields, saw 8\\nSkipping line 150: expected 4 fields, saw 8\\nSkipping line 151: expected 4 fields, saw 8\\nSkipping line 152: expected 4 fields, saw 8\\nSkipping line 153: expected 4 fields, saw 8\\nSkipping line 154: expected 4 fields, saw 8\\nSkipping line 155: expected 4 fields, saw 8\\nSkipping line 156: expected 4 fields, saw 8\\nSkipping line 157: expected 4 fields, saw 8\\nSkipping line 158: expected 4 fields, saw 8\\nSkipping line 159: expected 4 fields, saw 8\\nSkipping line 160: expected 4 fields, saw 8\\nSkipping line 161: expected 4 fields, saw 8\\nSkipping line 162: expected 4 fields, saw 8\\nSkipping line 163: expected 4 fields, saw 8\\nSkipping line 164: expected 4 fields, saw 8\\nSkipping line 165: expected 4 fields, saw 8\\nSkipping line 166: expected 4 fields, saw 8\\nSkipping line 167: expected 4 fields, saw 8\\nSkipping line 168: expected 4 fields, saw 8\\nSkipping line 169: expected 4 fields, saw 8\\nSkipping line 170: expected 4 fields, saw 8\\nSkipping line 171: expected 4 fields, saw 8\\nSkipping line 172: expected 4 fields, saw 8\\nSkipping line 173: expected 4 fields, saw 8\\nSkipping line 174: expected 4 fields, saw 8\\nSkipping line 175: expected 4 fields, saw 8\\nSkipping line 176: expected 4 fields, saw 8\\nSkipping line 177: expected 4 fields, saw 8\\nSkipping line 178: expected 4 fields, saw 8\\nSkipping line 179: expected 4 fields, saw 8\\nSkipping line 180: expected 4 fields, saw 8\\nSkipping line 181: expected 4 fields, saw 8\\nSkipping line 182: expected 4 fields, saw 8\\nSkipping line 183: expected 4 fields, saw 8\\nSkipping line 184: expected 4 fields, saw 8\\nSkipping line 185: expected 4 fields, saw 8\\nSkipping line 186: expected 4 fields, saw 8\\nSkipping line 187: expected 4 fields, saw 8\\nSkipping line 188: expected 4 fields, saw 8\\nSkipping line 189: expected 4 fields, saw 8\\nSkipping line 190: expected 4 fields, saw 8\\nSkipping line 191: expected 4 fields, saw 8\\nSkipping line 192: expected 4 fields, saw 8\\nSkipping line 193: expected 4 fields, saw 8\\nSkipping line 194: expected 4 fields, saw 8\\nSkipping line 195: expected 4 fields, saw 8\\nSkipping line 196: expected 4 fields, saw 8\\nSkipping line 197: expected 4 fields, saw 8\\nSkipping line 198: expected 4 fields, saw 8\\nSkipping line 199: expected 4 fields, saw 8\\nSkipping line 200: expected 4 fields, saw 8\\nSkipping line 201: expected 4 fields, saw 8\\nSkipping line 202: expected 4 fields, saw 8\\nSkipping line 203: expected 4 fields, saw 8\\nSkipping line 204: expected 4 fields, saw 8\\nSkipping line 205: expected 4 fields, saw 8\\nSkipping line 206: expected 4 fields, saw 8\\nSkipping line 207: expected 4 fields, saw 8\\nSkipping line 208: expected 4 fields, saw 8\\nSkipping line 209: expected 4 fields, saw 8\\nSkipping line 210: expected 4 fields, saw 8\\nSkipping line 211: expected 4 fields, saw 8\\nSkipping line 212: expected 4 fields, saw 8\\nSkipping line 213: expected 4 fields, saw 8\\nSkipping line 214: expected 4 fields, saw 8\\nSkipping line 215: expected 4 fields, saw 8\\nSkipping line 216: expected 4 fields, saw 8\\nSkipping line 217: expected 4 fields, saw 8\\nSkipping line 218: expected 4 fields, saw 8\\nSkipping line 219: expected 4 fields, saw 8\\nSkipping line 220: expected 4 fields, saw 8\\nSkipping line 221: expected 4 fields, saw 8\\nSkipping line 222: expected 4 fields, saw 8\\nSkipping line 223: expected 4 fields, saw 8\\nSkipping line 224: expected 4 fields, saw 8\\nSkipping line 225: expected 4 fields, saw 8\\nSkipping line 226: expected 4 fields, saw 8\\nSkipping line 227: expected 4 fields, saw 8\\nSkipping line 228: expected 4 fields, saw 8\\nSkipping line 229: expected 4 fields, saw 8\\nSkipping line 230: expected 4 fields, saw 8\\nSkipping line 231: expected 4 fields, saw 8\\nSkipping line 232: expected 4 fields, saw 8\\nSkipping line 233: expected 4 fields, saw 8\\nSkipping line 234: expected 4 fields, saw 8\\nSkipping line 235: expected 4 fields, saw 8\\nSkipping line 236: expected 4 fields, saw 8\\nSkipping line 237: expected 4 fields, saw 8\\nSkipping line 238: expected 4 fields, saw 8\\nSkipping line 239: expected 4 fields, saw 8\\nSkipping line 240: expected 4 fields, saw 8\\nSkipping line 241: expected 4 fields, saw 8\\nSkipping line 242: expected 4 fields, saw 8\\nSkipping line 243: expected 4 fields, saw 8\\nSkipping line 244: expected 4 fields, saw 8\\nSkipping line 245: expected 4 fields, saw 8\\nSkipping line 246: expected 4 fields, saw 8\\nSkipping line 247: expected 4 fields, saw 8\\nSkipping line 248: expected 4 fields, saw 8\\nSkipping line 249: expected 4 fields, saw 8\\nSkipping line 250: expected 4 fields, saw 8\\nSkipping line 251: expected 4 fields, saw 8\\nSkipping line 252: expected 4 fields, saw 8\\nSkipping line 253: expected 4 fields, saw 8\\nSkipping line 254: expected 4 fields, saw 8\\nSkipping line 255: expected 4 fields, saw 8\\nSkipping line 256: expected 4 fields, saw 8\\nSkipping line 257: expected 4 fields, saw 8\\nSkipping line 258: expected 4 fields, saw 8\\nSkipping line 259: expected 4 fields, saw 8\\nSkipping line 260: expected 4 fields, saw 8\\nSkipping line 261: expected 4 fields, saw 8\\nSkipping line 262: expected 4 fields, saw 8\\nSkipping line 263: expected 4 fields, saw 8\\nSkipping line 264: expected 4 fields, saw 8\\nSkipping line 265: expected 4 fields, saw 8\\nSkipping line 266: expected 4 fields, saw 8\\nSkipping line 267: expected 4 fields, saw 8\\nSkipping line 268: expected 4 fields, saw 8\\nSkipping line 269: expected 4 fields, saw 8\\nSkipping line 270: expected 4 fields, saw 8\\nSkipping line 271: expected 4 fields, saw 8\\nSkipping line 272: expected 4 fields, saw 8\\nSkipping line 273: expected 4 fields, saw 8\\nSkipping line 274: expected 4 fields, saw 8\\nSkipping line 275: expected 4 fields, saw 8\\nSkipping line 276: expected 4 fields, saw 8\\nSkipping line 277: expected 4 fields, saw 8\\nSkipping line 278: expected 4 fields, saw 8\\nSkipping line 279: expected 4 fields, saw 8\\nSkipping line 280: expected 4 fields, saw 8\\nSkipping line 281: expected 4 fields, saw 8\\nSkipping line 282: expected 4 fields, saw 8\\nSkipping line 283: expected 4 fields, saw 8\\nSkipping line 284: expected 4 fields, saw 8\\nSkipping line 285: expected 4 fields, saw 8\\nSkipping line 286: expected 4 fields, saw 8\\nSkipping line 287: expected 4 fields, saw 8\\nSkipping line 288: expected 4 fields, saw 8\\nSkipping line 289: expected 4 fields, saw 8\\nSkipping line 290: expected 4 fields, saw 8\\nSkipping line 291: expected 4 fields, saw 8\\nSkipping line 292: expected 4 fields, saw 8\\nSkipping line 293: expected 4 fields, saw 8\\nSkipping line 294: expected 4 fields, saw 8\\nSkipping line 295: expected 4 fields, saw 8\\nSkipping line 296: expected 4 fields, saw 8\\nSkipping line 297: expected 4 fields, saw 8\\nSkipping line 298: expected 4 fields, saw 8\\nSkipping line 299: expected 4 fields, saw 8\\nSkipping line 300: expected 4 fields, saw 8\\nSkipping line 301: expected 4 fields, saw 8\\nSkipping line 302: expected 4 fields, saw 8\\nSkipping line 303: expected 4 fields, saw 8\\nSkipping line 304: expected 4 fields, saw 8\\nSkipping line 305: expected 4 fields, saw 8\\nSkipping line 306: expected 4 fields, saw 8\\nSkipping line 307: expected 4 fields, saw 8\\nSkipping line 308: expected 4 fields, saw 8\\nSkipping line 309: expected 4 fields, saw 8\\nSkipping line 310: expected 4 fields, saw 8\\nSkipping line 311: expected 4 fields, saw 8\\nSkipping line 312: expected 4 fields, saw 8\\nSkipping line 313: expected 4 fields, saw 8\\nSkipping line 314: expected 4 fields, saw 8\\nSkipping line 315: expected 4 fields, saw 8\\nSkipping line 316: expected 4 fields, saw 8\\nSkipping line 317: expected 4 fields, saw 8\\nSkipping line 318: expected 4 fields, saw 8\\nSkipping line 319: expected 4 fields, saw 8\\nSkipping line 320: expected 4 fields, saw 8\\nSkipping line 321: expected 4 fields, saw 8\\nSkipping line 322: expected 4 fields, saw 8\\nSkipping line 323: expected 4 fields, saw 8\\nSkipping line 324: expected 4 fields, saw 8\\nSkipping line 325: expected 4 fields, saw 8\\nSkipping line 326: expected 4 fields, saw 8\\nSkipping line 327: expected 4 fields, saw 8\\nSkipping line 328: expected 4 fields, saw 8\\nSkipping line 329: expected 4 fields, saw 8\\nSkipping line 330: expected 4 fields, saw 8\\nSkipping line 331: expected 4 fields, saw 8\\nSkipping line 332: expected 4 fields, saw 8\\nSkipping line 333: expected 4 fields, saw 8\\nSkipping line 334: expected 4 fields, saw 8\\nSkipping line 335: expected 4 fields, saw 8\\nSkipping line 336: expected 4 fields, saw 8\\nSkipping line 337: expected 4 fields, saw 8\\nSkipping line 338: expected 4 fields, saw 8\\nSkipping line 339: expected 4 fields, saw 8\\nSkipping line 340: expected 4 fields, saw 8\\nSkipping line 341: expected 4 fields, saw 8\\nSkipping line 342: expected 4 fields, saw 8\\nSkipping line 343: expected 4 fields, saw 8\\nSkipping line 344: expected 4 fields, saw 8\\nSkipping line 345: expected 4 fields, saw 8\\nSkipping line 346: expected 4 fields, saw 8\\nSkipping line 347: expected 4 fields, saw 8\\nSkipping line 348: expected 4 fields, saw 8\\nSkipping line 349: expected 4 fields, saw 8\\nSkipping line 350: expected 4 fields, saw 8\\nSkipping line 351: expected 4 fields, saw 8\\nSkipping line 352: expected 4 fields, saw 8\\nSkipping line 353: expected 4 fields, saw 8\\nSkipping line 354: expected 4 fields, saw 8\\nSkipping line 355: expected 4 fields, saw 8\\nSkipping line 356: expected 4 fields, saw 8\\nSkipping line 357: expected 4 fields, saw 8\\nSkipping line 358: expected 4 fields, saw 8\\nSkipping line 359: expected 4 fields, saw 8\\nSkipping line 360: expected 4 fields, saw 8\\nSkipping line 361: expected 4 fields, saw 8\\nSkipping line 362: expected 4 fields, saw 8\\nSkipping line 363: expected 4 fields, saw 8\\nSkipping line 364: expected 4 fields, saw 8\\nSkipping line 365: expected 4 fields, saw 8\\nSkipping line 366: expected 4 fields, saw 8\\nSkipping line 367: expected 4 fields, saw 8\\nSkipping line 368: expected 4 fields, saw 8\\nSkipping line 369: expected 4 fields, saw 8\\nSkipping line 370: expected 4 fields, saw 8\\nSkipping line 371: expected 4 fields, saw 8\\nSkipping line 372: expected 4 fields, saw 8\\nSkipping line 373: expected 4 fields, saw 8\\nSkipping line 374: expected 4 fields, saw 8\\nSkipping line 375: expected 4 fields, saw 8\\nSkipping line 376: expected 4 fields, saw 8\\nSkipping line 377: expected 4 fields, saw 8\\nSkipping line 378: expected 4 fields, saw 8\\nSkipping line 379: expected 4 fields, saw 8\\nSkipping line 380: expected 4 fields, saw 8\\nSkipping line 381: expected 4 fields, saw 8\\nSkipping line 382: expected 4 fields, saw 8\\nSkipping line 383: expected 4 fields, saw 8\\nSkipping line 384: expected 4 fields, saw 8\\nSkipping line 385: expected 4 fields, saw 8\\nSkipping line 386: expected 4 fields, saw 8\\nSkipping line 387: expected 4 fields, saw 8\\nSkipping line 388: expected 4 fields, saw 8\\nSkipping line 389: expected 4 fields, saw 8\\nSkipping line 390: expected 4 fields, saw 8\\nSkipping line 391: expected 4 fields, saw 8\\nSkipping line 392: expected 4 fields, saw 8\\nSkipping line 393: expected 4 fields, saw 8\\nSkipping line 394: expected 4 fields, saw 8\\nSkipping line 395: expected 4 fields, saw 8\\nSkipping line 396: expected 4 fields, saw 8\\nSkipping line 397: expected 4 fields, saw 8\\nSkipping line 398: expected 4 fields, saw 8\\nSkipping line 399: expected 4 fields, saw 8\\nSkipping line 400: expected 4 fields, saw 8\\nSkipping line 401: expected 4 fields, saw 8\\nSkipping line 402: expected 4 fields, saw 8\\nSkipping line 403: expected 4 fields, saw 8\\nSkipping line 404: expected 4 fields, saw 8\\nSkipping line 405: expected 4 fields, saw 8\\nSkipping line 406: expected 4 fields, saw 8\\nSkipping line 407: expected 4 fields, saw 8\\nSkipping line 408: expected 4 fields, saw 8\\nSkipping line 409: expected 4 fields, saw 8\\nSkipping line 410: expected 4 fields, saw 8\\nSkipping line 411: expected 4 fields, saw 8\\nSkipping line 412: expected 4 fields, saw 8\\nSkipping line 413: expected 4 fields, saw 8\\nSkipping line 414: expected 4 fields, saw 8\\nSkipping line 415: expected 4 fields, saw 8\\nSkipping line 416: expected 4 fields, saw 8\\nSkipping line 417: expected 4 fields, saw 8\\nSkipping line 418: expected 4 fields, saw 8\\nSkipping line 419: expected 4 fields, saw 8\\nSkipping line 420: expected 4 fields, saw 8\\nSkipping line 421: expected 4 fields, saw 8\\nSkipping line 422: expected 4 fields, saw 8\\nSkipping line 423: expected 4 fields, saw 8\\nSkipping line 424: expected 4 fields, saw 8\\nSkipping line 425: expected 4 fields, saw 8\\nSkipping line 426: expected 4 fields, saw 8\\nSkipping line 427: expected 4 fields, saw 8\\nSkipping line 428: expected 4 fields, saw 8\\nSkipping line 429: expected 4 fields, saw 8\\nSkipping line 430: expected 4 fields, saw 8\\nSkipping line 431: expected 4 fields, saw 8\\nSkipping line 432: expected 4 fields, saw 8\\nSkipping line 433: expected 4 fields, saw 8\\nSkipping line 434: expected 4 fields, saw 8\\nSkipping line 435: expected 4 fields, saw 8\\nSkipping line 436: expected 4 fields, saw 8\\nSkipping line 437: expected 4 fields, saw 8\\nSkipping line 438: expected 4 fields, saw 8\\nSkipping line 439: expected 4 fields, saw 8\\nSkipping line 440: expected 4 fields, saw 8\\nSkipping line 441: expected 4 fields, saw 8\\nSkipping line 442: expected 4 fields, saw 8\\nSkipping line 443: expected 4 fields, saw 8\\nSkipping line 444: expected 4 fields, saw 8\\nSkipping line 445: expected 4 fields, saw 8\\nSkipping line 446: expected 4 fields, saw 8\\nSkipping line 447: expected 4 fields, saw 8\\nSkipping line 448: expected 4 fields, saw 8\\nSkipping line 449: expected 4 fields, saw 8\\nSkipping line 450: expected 4 fields, saw 8\\nSkipping line 451: expected 4 fields, saw 8\\nSkipping line 452: expected 4 fields, saw 8\\nSkipping line 453: expected 4 fields, saw 8\\nSkipping line 454: expected 4 fields, saw 8\\nSkipping line 455: expected 4 fields, saw 8\\nSkipping line 456: expected 4 fields, saw 8\\nSkipping line 457: expected 4 fields, saw 8\\nSkipping line 458: expected 4 fields, saw 8\\nSkipping line 459: expected 4 fields, saw 8\\nSkipping line 460: expected 4 fields, saw 8\\nSkipping line 461: expected 4 fields, saw 8\\nSkipping line 462: expected 4 fields, saw 8\\nSkipping line 463: expected 4 fields, saw 8\\nSkipping line 464: expected 4 fields, saw 8\\nSkipping line 465: expected 4 fields, saw 8\\nSkipping line 466: expected 4 fields, saw 8\\nSkipping line 467: expected 4 fields, saw 8\\nSkipping line 468: expected 4 fields, saw 8\\nSkipping line 469: expected 4 fields, saw 8\\nSkipping line 470: expected 4 fields, saw 8\\nSkipping line 471: expected 4 fields, saw 8\\nSkipping line 472: expected 4 fields, saw 8\\nSkipping line 473: expected 4 fields, saw 8\\nSkipping line 474: expected 4 fields, saw 8\\nSkipping line 475: expected 4 fields, saw 8\\nSkipping line 476: expected 4 fields, saw 8\\nSkipping line 477: expected 4 fields, saw 8\\nSkipping line 478: expected 4 fields, saw 8\\nSkipping line 479: expected 4 fields, saw 8\\nSkipping line 480: expected 4 fields, saw 8\\nSkipping line 481: expected 4 fields, saw 8\\nSkipping line 482: expected 4 fields, saw 8\\nSkipping line 483: expected 4 fields, saw 8\\nSkipping line 484: expected 4 fields, saw 8\\nSkipping line 485: expected 4 fields, saw 8\\nSkipping line 486: expected 4 fields, saw 8\\nSkipping line 487: expected 4 fields, saw 8\\nSkipping line 488: expected 4 fields, saw 8\\nSkipping line 489: expected 4 fields, saw 8\\nSkipping line 490: expected 4 fields, saw 8\\nSkipping line 491: expected 4 fields, saw 8\\nSkipping line 492: expected 4 fields, saw 8\\nSkipping line 493: expected 4 fields, saw 8\\nSkipping line 494: expected 4 fields, saw 8\\nSkipping line 495: expected 4 fields, saw 8\\nSkipping line 496: expected 4 fields, saw 8\\nSkipping line 497: expected 4 fields, saw 8\\nSkipping line 498: expected 4 fields, saw 8\\nSkipping line 499: expected 4 fields, saw 8\\nSkipping line 500: expected 4 fields, saw 8\\nSkipping line 501: expected 4 fields, saw 8\\nSkipping line 502: expected 4 fields, saw 8\\nSkipping line 503: expected 4 fields, saw 8\\nSkipping line 504: expected 4 fields, saw 8\\nSkipping line 505: expected 4 fields, saw 8\\nSkipping line 506: expected 4 fields, saw 8\\nSkipping line 507: expected 4 fields, saw 8\\nSkipping line 508: expected 4 fields, saw 8\\nSkipping line 509: expected 4 fields, saw 8\\nSkipping line 510: expected 4 fields, saw 8\\nSkipping line 511: expected 4 fields, saw 8\\nSkipping line 512: expected 4 fields, saw 8\\nSkipping line 513: expected 4 fields, saw 8\\nSkipping line 514: expected 4 fields, saw 8\\nSkipping line 515: expected 4 fields, saw 8\\nSkipping line 516: expected 4 fields, saw 8\\nSkipping line 517: expected 4 fields, saw 8\\nSkipping line 518: expected 4 fields, saw 8\\nSkipping line 519: expected 4 fields, saw 8\\nSkipping line 520: expected 4 fields, saw 8\\nSkipping line 521: expected 4 fields, saw 8\\nSkipping line 522: expected 4 fields, saw 8\\nSkipping line 523: expected 4 fields, saw 8\\nSkipping line 524: expected 4 fields, saw 8\\nSkipping line 525: expected 4 fields, saw 8\\nSkipping line 526: expected 4 fields, saw 8\\nSkipping line 527: expected 4 fields, saw 8\\nSkipping line 528: expected 4 fields, saw 8\\nSkipping line 529: expected 4 fields, saw 8\\nSkipping line 530: expected 4 fields, saw 8\\nSkipping line 531: expected 4 fields, saw 8\\nSkipping line 532: expected 4 fields, saw 8\\nSkipping line 533: expected 4 fields, saw 8\\nSkipping line 534: expected 4 fields, saw 8\\nSkipping line 535: expected 4 fields, saw 8\\nSkipping line 536: expected 4 fields, saw 8\\nSkipping line 537: expected 4 fields, saw 8\\nSkipping line 538: expected 4 fields, saw 8\\nSkipping line 539: expected 4 fields, saw 8\\nSkipping line 540: expected 4 fields, saw 8\\nSkipping line 541: expected 4 fields, saw 8\\nSkipping line 542: expected 4 fields, saw 8\\nSkipping line 543: expected 4 fields, saw 8\\nSkipping line 544: expected 4 fields, saw 8\\nSkipping line 545: expected 4 fields, saw 8\\nSkipping line 546: expected 4 fields, saw 8\\nSkipping line 547: expected 4 fields, saw 8\\nSkipping line 548: expected 4 fields, saw 8\\nSkipping line 549: expected 4 fields, saw 8\\nSkipping line 550: expected 4 fields, saw 8\\nSkipping line 551: expected 4 fields, saw 8\\nSkipping line 552: expected 4 fields, saw 8\\nSkipping line 553: expected 4 fields, saw 8\\nSkipping line 554: expected 4 fields, saw 8\\nSkipping line 555: expected 4 fields, saw 8\\nSkipping line 556: expected 4 fields, saw 8\\nSkipping line 557: expected 4 fields, saw 8\\nSkipping line 558: expected 4 fields, saw 8\\nSkipping line 559: expected 4 fields, saw 8\\nSkipping line 560: expected 4 fields, saw 8\\nSkipping line 561: expected 4 fields, saw 8\\nSkipping line 562: expected 4 fields, saw 8\\nSkipping line 563: expected 4 fields, saw 8\\nSkipping line 564: expected 4 fields, saw 8\\nSkipping line 565: expected 4 fields, saw 8\\nSkipping line 566: expected 4 fields, saw 8\\nSkipping line 567: expected 4 fields, saw 8\\nSkipping line 568: expected 4 fields, saw 8\\nSkipping line 569: expected 4 fields, saw 8\\nSkipping line 570: expected 4 fields, saw 8\\nSkipping line 571: expected 4 fields, saw 8\\nSkipping line 572: expected 4 fields, saw 8\\nSkipping line 573: expected 4 fields, saw 8\\nSkipping line 574: expected 4 fields, saw 8\\nSkipping line 575: expected 4 fields, saw 8\\nSkipping line 576: expected 4 fields, saw 8\\nSkipping line 577: expected 4 fields, saw 8\\nSkipping line 578: expected 4 fields, saw 8\\nSkipping line 579: expected 4 fields, saw 8\\nSkipping line 580: expected 4 fields, saw 8\\nSkipping line 581: expected 4 fields, saw 8\\nSkipping line 582: expected 4 fields, saw 8\\nSkipping line 583: expected 4 fields, saw 8\\nSkipping line 584: expected 4 fields, saw 8\\nSkipping line 585: expected 4 fields, saw 8\\nSkipping line 586: expected 4 fields, saw 8\\nSkipping line 587: expected 4 fields, saw 8\\nSkipping line 588: expected 4 fields, saw 8\\nSkipping line 589: expected 4 fields, saw 8\\nSkipping line 590: expected 4 fields, saw 8\\nSkipping line 591: expected 4 fields, saw 8\\nSkipping line 592: expected 4 fields, saw 8\\nSkipping line 593: expected 4 fields, saw 8\\nSkipping line 594: expected 4 fields, saw 8\\nSkipping line 595: expected 4 fields, saw 8\\nSkipping line 596: expected 4 fields, saw 8\\nSkipping line 597: expected 4 fields, saw 8\\nSkipping line 598: expected 4 fields, saw 8\\nSkipping line 599: expected 4 fields, saw 8\\nSkipping line 600: expected 4 fields, saw 8\\nSkipping line 601: expected 4 fields, saw 8\\nSkipping line 602: expected 4 fields, saw 8\\nSkipping line 603: expected 4 fields, saw 8\\nSkipping line 604: expected 4 fields, saw 8\\nSkipping line 605: expected 4 fields, saw 8\\nSkipping line 606: expected 4 fields, saw 8\\nSkipping line 607: expected 4 fields, saw 8\\nSkipping line 608: expected 4 fields, saw 8\\nSkipping line 609: expected 4 fields, saw 8\\nSkipping line 610: expected 4 fields, saw 8\\nSkipping line 611: expected 4 fields, saw 8\\nSkipping line 612: expected 4 fields, saw 8\\nSkipping line 613: expected 4 fields, saw 8\\nSkipping line 614: expected 4 fields, saw 8\\nSkipping line 615: expected 4 fields, saw 8\\nSkipping line 616: expected 4 fields, saw 8\\nSkipping line 617: expected 4 fields, saw 8\\nSkipping line 618: expected 4 fields, saw 8\\nSkipping line 619: expected 4 fields, saw 8\\nSkipping line 620: expected 4 fields, saw 8\\nSkipping line 621: expected 4 fields, saw 8\\nSkipping line 622: expected 4 fields, saw 8\\nSkipping line 623: expected 4 fields, saw 8\\nSkipping line 624: expected 4 fields, saw 8\\nSkipping line 625: expected 4 fields, saw 8\\nSkipping line 626: expected 4 fields, saw 8\\nSkipping line 627: expected 4 fields, saw 8\\nSkipping line 628: expected 4 fields, saw 8\\nSkipping line 629: expected 4 fields, saw 8\\nSkipping line 630: expected 4 fields, saw 8\\nSkipping line 631: expected 4 fields, saw 8\\nSkipping line 632: expected 4 fields, saw 8\\nSkipping line 633: expected 4 fields, saw 8\\nSkipping line 634: expected 4 fields, saw 8\\nSkipping line 635: expected 4 fields, saw 8\\nSkipping line 636: expected 4 fields, saw 8\\nSkipping line 637: expected 4 fields, saw 8\\nSkipping line 638: expected 4 fields, saw 8\\nSkipping line 639: expected 4 fields, saw 8\\nSkipping line 640: expected 4 fields, saw 8\\nSkipping line 641: expected 4 fields, saw 8\\nSkipping line 642: expected 4 fields, saw 8\\nSkipping line 643: expected 4 fields, saw 8\\nSkipping line 644: expected 4 fields, saw 8\\nSkipping line 645: expected 4 fields, saw 8\\nSkipping line 646: expected 4 fields, saw 8\\nSkipping line 647: expected 4 fields, saw 8\\nSkipping line 648: expected 4 fields, saw 8\\nSkipping line 649: expected 4 fields, saw 8\\nSkipping line 650: expected 4 fields, saw 8\\nSkipping line 651: expected 4 fields, saw 8\\nSkipping line 652: expected 4 fields, saw 8\\nSkipping line 653: expected 4 fields, saw 8\\nSkipping line 654: expected 4 fields, saw 8\\nSkipping line 655: expected 4 fields, saw 8\\nSkipping line 656: expected 4 fields, saw 8\\nSkipping line 657: expected 4 fields, saw 8\\nSkipping line 658: expected 4 fields, saw 8\\nSkipping line 659: expected 4 fields, saw 8\\nSkipping line 660: expected 4 fields, saw 8\\nSkipping line 661: expected 4 fields, saw 8\\nSkipping line 662: expected 4 fields, saw 8\\nSkipping line 663: expected 4 fields, saw 8\\nSkipping line 664: expected 4 fields, saw 8\\nSkipping line 665: expected 4 fields, saw 8\\nSkipping line 666: expected 4 fields, saw 8\\nSkipping line 667: expected 4 fields, saw 8\\nSkipping line 668: expected 4 fields, saw 8\\nSkipping line 669: expected 4 fields, saw 8\\nSkipping line 670: expected 4 fields, saw 8\\nSkipping line 671: expected 4 fields, saw 8\\nSkipping line 672: expected 4 fields, saw 8\\nSkipping line 673: expected 4 fields, saw 8\\nSkipping line 674: expected 4 fields, saw 8\\nSkipping line 675: expected 4 fields, saw 8\\nSkipping line 676: expected 4 fields, saw 8\\nSkipping line 677: expected 4 fields, saw 8\\nSkipping line 678: expected 4 fields, saw 8\\nSkipping line 679: expected 4 fields, saw 8\\nSkipping line 680: expected 4 fields, saw 8\\nSkipping line 681: expected 4 fields, saw 8\\nSkipping line 682: expected 4 fields, saw 8\\nSkipping line 683: expected 4 fields, saw 8\\nSkipping line 684: expected 4 fields, saw 8\\nSkipping line 685: expected 4 fields, saw 8\\nSkipping line 686: expected 4 fields, saw 8\\nSkipping line 687: expected 4 fields, saw 8\\nSkipping line 688: expected 4 fields, saw 8\\nSkipping line 689: expected 4 fields, saw 8\\nSkipping line 690: expected 4 fields, saw 8\\nSkipping line 691: expected 4 fields, saw 8\\nSkipping line 692: expected 4 fields, saw 8\\nSkipping line 693: expected 4 fields, saw 8\\nSkipping line 694: expected 4 fields, saw 8\\nSkipping line 695: expected 4 fields, saw 8\\nSkipping line 696: expected 4 fields, saw 8\\nSkipping line 697: expected 4 fields, saw 8\\nSkipping line 698: expected 4 fields, saw 8\\nSkipping line 699: expected 4 fields, saw 8\\nSkipping line 700: expected 4 fields, saw 8\\nSkipping line 701: expected 4 fields, saw 8\\nSkipping line 702: expected 4 fields, saw 8\\nSkipping line 703: expected 4 fields, saw 8\\nSkipping line 704: expected 4 fields, saw 8\\nSkipping line 705: expected 4 fields, saw 8\\nSkipping line 706: expected 4 fields, saw 8\\nSkipping line 707: expected 4 fields, saw 8\\nSkipping line 708: expected 4 fields, saw 8\\nSkipping line 709: expected 4 fields, saw 8\\nSkipping line 710: expected 4 fields, saw 8\\nSkipping line 711: expected 4 fields, saw 8\\nSkipping line 712: expected 4 fields, saw 8\\nSkipping line 713: expected 4 fields, saw 8\\nSkipping line 714: expected 4 fields, saw 8\\nSkipping line 715: expected 4 fields, saw 8\\nSkipping line 716: expected 4 fields, saw 8\\nSkipping line 717: expected 4 fields, saw 8\\nSkipping line 718: expected 4 fields, saw 8\\nSkipping line 719: expected 4 fields, saw 8\\nSkipping line 720: expected 4 fields, saw 8\\nSkipping line 721: expected 4 fields, saw 8\\nSkipping line 722: expected 4 fields, saw 8\\nSkipping line 723: expected 4 fields, saw 8\\nSkipping line 724: expected 4 fields, saw 8\\nSkipping line 725: expected 4 fields, saw 8\\nSkipping line 726: expected 4 fields, saw 8\\nSkipping line 727: expected 4 fields, saw 8\\nSkipping line 728: expected 4 fields, saw 8\\nSkipping line 729: expected 4 fields, saw 8\\nSkipping line 730: expected 4 fields, saw 8\\nSkipping line 731: expected 4 fields, saw 8\\nSkipping line 732: expected 4 fields, saw 8\\nSkipping line 733: expected 4 fields, saw 8\\nSkipping line 734: expected 4 fields, saw 8\\nSkipping line 735: expected 4 fields, saw 8\\nSkipping line 736: expected 4 fields, saw 8\\nSkipping line 737: expected 4 fields, saw 8\\nSkipping line 738: expected 4 fields, saw 8\\nSkipping line 739: expected 4 fields, saw 8\\nSkipping line 740: expected 4 fields, saw 8\\nSkipping line 741: expected 4 fields, saw 8\\nSkipping line 742: expected 4 fields, saw 8\\nSkipping line 743: expected 4 fields, saw 8\\nSkipping line 744: expected 4 fields, saw 8\\nSkipping line 745: expected 4 fields, saw 8\\nSkipping line 746: expected 4 fields, saw 8\\nSkipping line 747: expected 4 fields, saw 8\\nSkipping line 748: expected 4 fields, saw 8\\nSkipping line 749: expected 4 fields, saw 8\\nSkipping line 750: expected 4 fields, saw 8\\nSkipping line 751: expected 4 fields, saw 8\\nSkipping line 752: expected 4 fields, saw 8\\nSkipping line 753: expected 4 fields, saw 8\\nSkipping line 754: expected 4 fields, saw 8\\nSkipping line 755: expected 4 fields, saw 8\\nSkipping line 756: expected 4 fields, saw 8\\nSkipping line 757: expected 4 fields, saw 8\\nSkipping line 758: expected 4 fields, saw 8\\nSkipping line 759: expected 4 fields, saw 8\\nSkipping line 760: expected 4 fields, saw 8\\nSkipping line 761: expected 4 fields, saw 8\\nSkipping line 762: expected 4 fields, saw 8\\nSkipping line 763: expected 4 fields, saw 8\\nSkipping line 764: expected 4 fields, saw 8\\nSkipping line 765: expected 4 fields, saw 8\\nSkipping line 766: expected 4 fields, saw 8\\nSkipping line 767: expected 4 fields, saw 8\\nSkipping line 768: expected 4 fields, saw 8\\nSkipping line 769: expected 4 fields, saw 8\\nSkipping line 770: expected 4 fields, saw 8\\nSkipping line 771: expected 4 fields, saw 8\\nSkipping line 772: expected 4 fields, saw 8\\nSkipping line 773: expected 4 fields, saw 8\\nSkipping line 774: expected 4 fields, saw 8\\nSkipping line 775: expected 4 fields, saw 8\\nSkipping line 776: expected 4 fields, saw 8\\nSkipping line 777: expected 4 fields, saw 8\\nSkipping line 778: expected 4 fields, saw 8\\nSkipping line 779: expected 4 fields, saw 8\\nSkipping line 780: expected 4 fields, saw 8\\nSkipping line 781: expected 4 fields, saw 8\\nSkipping line 782: expected 4 fields, saw 8\\nSkipping line 783: expected 4 fields, saw 8\\nSkipping line 784: expected 4 fields, saw 8\\nSkipping line 785: expected 4 fields, saw 8\\nSkipping line 786: expected 4 fields, saw 8\\nSkipping line 787: expected 4 fields, saw 8\\nSkipping line 788: expected 4 fields, saw 8\\nSkipping line 789: expected 4 fields, saw 8\\nSkipping line 790: expected 4 fields, saw 8\\nSkipping line 791: expected 4 fields, saw 8\\nSkipping line 792: expected 4 fields, saw 8\\nSkipping line 793: expected 4 fields, saw 8\\nSkipping line 794: expected 4 fields, saw 8\\nSkipping line 795: expected 4 fields, saw 8\\nSkipping line 796: expected 4 fields, saw 8\\nSkipping line 797: expected 4 fields, saw 8\\nSkipping line 798: expected 4 fields, saw 8\\nSkipping line 799: expected 4 fields, saw 8\\nSkipping line 800: expected 4 fields, saw 8\\nSkipping line 801: expected 4 fields, saw 8\\nSkipping line 802: expected 4 fields, saw 8\\nSkipping line 803: expected 4 fields, saw 8\\nSkipping line 804: expected 4 fields, saw 8\\nSkipping line 805: expected 4 fields, saw 8\\nSkipping line 806: expected 4 fields, saw 8\\nSkipping line 807: expected 4 fields, saw 8\\nSkipping line 808: expected 4 fields, saw 8\\nSkipping line 809: expected 4 fields, saw 8\\nSkipping line 810: expected 4 fields, saw 8\\nSkipping line 811: expected 4 fields, saw 8\\nSkipping line 812: expected 4 fields, saw 8\\nSkipping line 813: expected 4 fields, saw 8\\nSkipping line 814: expected 4 fields, saw 8\\nSkipping line 815: expected 4 fields, saw 8\\nSkipping line 816: expected 4 fields, saw 8\\nSkipping line 817: expected 4 fields, saw 8\\nSkipping line 818: expected 4 fields, saw 8\\nSkipping line 819: expected 4 fields, saw 8\\nSkipping line 820: expected 4 fields, saw 8\\nSkipping line 821: expected 4 fields, saw 8\\nSkipping line 822: expected 4 fields, saw 8\\nSkipping line 823: expected 4 fields, saw 8\\nSkipping line 824: expected 4 fields, saw 8\\nSkipping line 825: expected 4 fields, saw 8\\nSkipping line 826: expected 4 fields, saw 8\\nSkipping line 827: expected 4 fields, saw 8\\nSkipping line 828: expected 4 fields, saw 8\\nSkipping line 829: expected 4 fields, saw 8\\nSkipping line 830: expected 4 fields, saw 8\\nSkipping line 831: expected 4 fields, saw 8\\nSkipping line 832: expected 4 fields, saw 8\\nSkipping line 833: expected 4 fields, saw 8\\nSkipping line 834: expected 4 fields, saw 8\\nSkipping line 835: expected 4 fields, saw 8\\nSkipping line 836: expected 4 fields, saw 8\\nSkipping line 837: expected 4 fields, saw 8\\nSkipping line 838: expected 4 fields, saw 8\\nSkipping line 839: expected 4 fields, saw 8\\nSkipping line 840: expected 4 fields, saw 8\\nSkipping line 841: expected 4 fields, saw 8\\nSkipping line 842: expected 4 fields, saw 8\\nSkipping line 843: expected 4 fields, saw 8\\nSkipping line 844: expected 4 fields, saw 8\\nSkipping line 845: expected 4 fields, saw 8\\nSkipping line 846: expected 4 fields, saw 8\\nSkipping line 847: expected 4 fields, saw 8\\nSkipping line 848: expected 4 fields, saw 8\\nSkipping line 849: expected 4 fields, saw 8\\nSkipping line 850: expected 4 fields, saw 8\\nSkipping line 851: expected 4 fields, saw 8\\nSkipping line 852: expected 4 fields, saw 8\\nSkipping line 853: expected 4 fields, saw 8\\nSkipping line 854: expected 4 fields, saw 8\\nSkipping line 855: expected 4 fields, saw 8\\nSkipping line 856: expected 4 fields, saw 8\\nSkipping line 857: expected 4 fields, saw 8\\nSkipping line 858: expected 4 fields, saw 8\\nSkipping line 859: expected 4 fields, saw 8\\nSkipping line 860: expected 4 fields, saw 8\\nSkipping line 861: expected 4 fields, saw 8\\nSkipping line 862: expected 4 fields, saw 8\\nSkipping line 863: expected 4 fields, saw 8\\nSkipping line 864: expected 4 fields, saw 8\\nSkipping line 865: expected 4 fields, saw 8\\nSkipping line 866: expected 4 fields, saw 8\\nSkipping line 867: expected 4 fields, saw 8\\nSkipping line 868: expected 4 fields, saw 8\\nSkipping line 869: expected 4 fields, saw 8\\nSkipping line 870: expected 4 fields, saw 8\\nSkipping line 871: expected 4 fields, saw 8\\nSkipping line 872: expected 4 fields, saw 8\\nSkipping line 873: expected 4 fields, saw 8\\nSkipping line 874: expected 4 fields, saw 8\\nSkipping line 875: expected 4 fields, saw 8\\nSkipping line 876: expected 4 fields, saw 8\\nSkipping line 877: expected 4 fields, saw 8\\nSkipping line 878: expected 4 fields, saw 8\\nSkipping line 879: expected 4 fields, saw 8\\nSkipping line 880: expected 4 fields, saw 8\\nSkipping line 881: expected 4 fields, saw 8\\nSkipping line 882: expected 4 fields, saw 8\\nSkipping line 883: expected 4 fields, saw 8\\nSkipping line 884: expected 4 fields, saw 8\\nSkipping line 885: expected 4 fields, saw 8\\nSkipping line 886: expected 4 fields, saw 8\\nSkipping line 887: expected 4 fields, saw 8\\nSkipping line 888: expected 4 fields, saw 8\\nSkipping line 889: expected 4 fields, saw 8\\nSkipping line 890: expected 4 fields, saw 8\\nSkipping line 891: expected 4 fields, saw 8\\nSkipping line 892: expected 4 fields, saw 8\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>userID</th>\n",
       "      <th>logged</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>81.71.4.55</td>\n",
       "      <td>1388518491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>81.71.4.55</td>\n",
       "      <td>1388518469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>83.84.78.163</td>\n",
       "      <td>1388591989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2.125.14.193</td>\n",
       "      <td>1388785531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>195.240.183.161</td>\n",
       "      <td>1388619667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>98.15.189.166</td>\n",
       "      <td>1388785543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>2.125.14.193</td>\n",
       "      <td>1388785545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>178.167.243.117</td>\n",
       "      <td>1388785662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>109.158.251.94</td>\n",
       "      <td>1388787488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>109.158.251.94</td>\n",
       "      <td>1388787493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>90.223.205.134</td>\n",
       "      <td>1389013584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>74</td>\n",
       "      <td>90.223.205.134</td>\n",
       "      <td>1390943080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  userID           logged        date\n",
       "0    5      13       81.71.4.55  1388518491\n",
       "1    4      13       81.71.4.55  1388518469\n",
       "2    6      13     83.84.78.163  1388591989\n",
       "3   12      46     2.125.14.193  1388785531\n",
       "4    9      13  195.240.183.161  1388619667\n",
       "5   13      46    98.15.189.166  1388785543\n",
       "6   14      46     2.125.14.193  1388785545\n",
       "7   15      46  178.167.243.117  1388785662\n",
       "8   16      46   109.158.251.94  1388787488\n",
       "9   17      46   109.158.251.94  1388787493\n",
       "10  21      37   90.223.205.134  1389013584\n",
       "11  22      74   90.223.205.134  1390943080"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='logs'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? NO\n",
    "    - This table looks like: users\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o \n",
    "    - On the column name:\n",
    "        o email -> useremail \n",
    "        o membership -> planid\n",
    "    - Add required columns:\n",
    "        o userid\n",
    "        o expire\n",
    "    - Split columns:\n",
    "        o df_logins['username']=df_users['username']\n",
    "        o df_logins['userip']=df_users['ip']\n",
    "        o df_logins['date']=timestamp2datetime(df_users['lastlogin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7. Table: 'news'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Welcome to the new and improved NotoriousBoot ...</td>\n",
       "      <td>1388652653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Power issue is resolved any problems open a ti...</td>\n",
       "      <td>1388652682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Skype resolver resolves alot faster and pulls ...</td>\n",
       "      <td>1388652691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Any donations are welcome send them here abase...</td>\n",
       "      <td>1391005526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Any problems with accounts / power please cont...</td>\n",
       "      <td>1388763412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>All power problems are fucked new AMP / NTP Li...</td>\n",
       "      <td>1391005567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Check out support on navigation if any help is...</td>\n",
       "      <td>1391005611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>We have switched hosting provider so site shou...</td>\n",
       "      <td>1391351394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Fixed Skype Resolver it should be more accurat...</td>\n",
       "      <td>1391351667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              title        date\n",
       "0   1  Welcome to the new and improved NotoriousBoot ...  1388652653\n",
       "1   2  Power issue is resolved any problems open a ti...  1388652682\n",
       "2   3  Skype resolver resolves alot faster and pulls ...  1388652691\n",
       "3   6  Any donations are welcome send them here abase...  1391005526\n",
       "4   5  Any problems with accounts / power please cont...  1388763412\n",
       "5   7  All power problems are fucked new AMP / NTP Li...  1391005567\n",
       "6   8  Check out support on navigation if any help is...  1391005611\n",
       "7   9  We have switched hosting provider so site shou...  1391351394\n",
       "8  10  Fixed Skype Resolver it should be more accurat...  1391351667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='news'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? NO\n",
    "    - This table looks like: \n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o \n",
    "    - On the column name:\n",
    "        o \n",
    "    - Add required columns:\n",
    "        o \n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8. Table: 'payments'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>paid</th>\n",
       "      <th>plan</th>\n",
       "      <th>user</th>\n",
       "      <th>email</th>\n",
       "      <th>tid</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>ipdump@outlook.com</td>\n",
       "      <td>67K6343777463533P</td>\n",
       "      <td>1390934463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "      <td>dude5606@yahoo.com</td>\n",
       "      <td>5YF61251GM140642M</td>\n",
       "      <td>1391204724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  paid  plan  user               email                tid        date\n",
       "0   1    16     7    91  ipdump@outlook.com  67K6343777463533P  1390934463\n",
       "1   2    21     8   122  dude5606@yahoo.com  5YF61251GM140642M  1391204724"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='payments'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES \n",
    "    - This table looks like: payments\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o date -> timestamp2datetime()\n",
    "    - On the column name:\n",
    "        o ID -> id\n",
    "        o user -> userid\n",
    "        o paid -> amountpaid \n",
    "        o email -> paymentemail \n",
    "        o plan -> planid\n",
    "    - Add required columns:\n",
    "        o username\n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'payments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amountpaid</th>\n",
       "      <th>planid</th>\n",
       "      <th>userid</th>\n",
       "      <th>paymentemail</th>\n",
       "      <th>tid</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>ipdump@outlook.com</td>\n",
       "      <td>67K6343777463533P</td>\n",
       "      <td>2014-01-28 18:41:03</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "      <td>dude5606@yahoo.com</td>\n",
       "      <td>5YF61251GM140642M</td>\n",
       "      <td>2014-01-31 21:45:24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  amountpaid  planid  userid        paymentemail                tid  \\\n",
       "0   1          16       7      91  ipdump@outlook.com  67K6343777463533P   \n",
       "1   2          21       8     122  dude5606@yahoo.com  5YF61251GM140642M   \n",
       "\n",
       "                 date username  \n",
       "0 2014-01-28 18:41:03           \n",
       "1 2014-01-31 21:45:24           "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_payments = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "df_payments['date'] = timestamp2datetime(df_payments['date']) \n",
    "\n",
    "# Changing names of columns\n",
    "df_payments.rename(inplace=True, columns = {'ID':'id',\n",
    "                                           'user':'userid',\n",
    "                                           'paid': 'amountpaid',\n",
    "                                           'email': 'paymentemail',\n",
    "                                           'plan':'planid'})\n",
    "\n",
    "# Creating empty columns (with \"\" [for future string] or np.nan [for future float])\n",
    "df_payments['username']=''\n",
    "\n",
    "\n",
    "# Showing some lines after adapt the table\n",
    "df_payments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9. Table: 'plans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>mbt</th>\n",
       "      <th>unit</th>\n",
       "      <th>length</th>\n",
       "      <th>price</th>\n",
       "      <th>concurrents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sierra (Life</td>\n",
       "      <td>7200</td>\n",
       "      <td>Years</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Alpha (1/m</td>\n",
       "      <td>120</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Bravo (1/m</td>\n",
       "      <td>300</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie (1/m</td>\n",
       "      <td>600</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Delta (1/m</td>\n",
       "      <td>900</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Echo (1/m</td>\n",
       "      <td>1200</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Foxtrot (1/m</td>\n",
       "      <td>1600</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Golf (3/m</td>\n",
       "      <td>1900</td>\n",
       "      <td>Months</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Hotel (3/m</td>\n",
       "      <td>2300</td>\n",
       "      <td>Months</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>India (3/m</td>\n",
       "      <td>2600</td>\n",
       "      <td>Months</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          name   mbt    unit  length  price  concurrents\n",
       "0   1  Sierra (Life  7200   Years      12    200           15\n",
       "1   3    Alpha (1/m   120  Months       1      3            1\n",
       "2   4    Bravo (1/m   300  Months       1      5            1\n",
       "3   5  Charlie (1/m   600  Months       1      8            1\n",
       "4   6    Delta (1/m   900  Months       1     13            1\n",
       "5   7     Echo (1/m  1200  Months       1     16            1\n",
       "6   8  Foxtrot (1/m  1600  Months       1     21            1\n",
       "7   9     Golf (3/m  1900  Months       3     30            2\n",
       "8  10    Hotel (3/m  2300  Months       3     35            2\n",
       "9  11    India (3/m  2600  Months       3     45            2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='plans'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES\n",
    "    - This table looks like: plans\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o \n",
    "    - On the column name:\n",
    "        o ID -> planid\n",
    "        o name -> planname \n",
    "        o mbt -> maxboottime \n",
    "        o concurrents -> concurrecy\n",
    "    - Add required columns:\n",
    "        o plandescr\n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'plans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planid</th>\n",
       "      <th>planname</th>\n",
       "      <th>maxboottime</th>\n",
       "      <th>unit</th>\n",
       "      <th>length</th>\n",
       "      <th>price</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>plandescr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sierra (Life</td>\n",
       "      <td>7200</td>\n",
       "      <td>Years</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Alpha (1/m</td>\n",
       "      <td>120</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Bravo (1/m</td>\n",
       "      <td>300</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie (1/m</td>\n",
       "      <td>600</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Delta (1/m</td>\n",
       "      <td>900</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Echo (1/m</td>\n",
       "      <td>1200</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Foxtrot (1/m</td>\n",
       "      <td>1600</td>\n",
       "      <td>Months</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Golf (3/m</td>\n",
       "      <td>1900</td>\n",
       "      <td>Months</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Hotel (3/m</td>\n",
       "      <td>2300</td>\n",
       "      <td>Months</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>India (3/m</td>\n",
       "      <td>2600</td>\n",
       "      <td>Months</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   planid      planname  maxboottime    unit  length  price  concurrency  \\\n",
       "0       1  Sierra (Life         7200   Years      12    200           15   \n",
       "1       3    Alpha (1/m          120  Months       1      3            1   \n",
       "2       4    Bravo (1/m          300  Months       1      5            1   \n",
       "3       5  Charlie (1/m          600  Months       1      8            1   \n",
       "4       6    Delta (1/m          900  Months       1     13            1   \n",
       "5       7     Echo (1/m         1200  Months       1     16            1   \n",
       "6       8  Foxtrot (1/m         1600  Months       1     21            1   \n",
       "7       9     Golf (3/m         1900  Months       3     30            2   \n",
       "8      10    Hotel (3/m         2300  Months       3     35            2   \n",
       "9      11    India (3/m         2600  Months       3     45            2   \n",
       "\n",
       "  plandescr  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            \n",
       "5            \n",
       "6            \n",
       "7            \n",
       "8            \n",
       "9            "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_plans = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "\n",
    "\n",
    "# Changing names of columns\n",
    "df_plans.rename(inplace=True, columns = {'ID': 'planid',\n",
    "                                        'name':'planname',\n",
    "                                        'mbt': 'maxboottime',\n",
    "                                        'concurrents':'concurrency'})\n",
    "\n",
    "# Creating empty columns (with \"\" [for future string] or np.nan [for future float])\n",
    "df_plans['plandescr']=''\n",
    "\n",
    "# Showing some lines after adapt the table\n",
    "df_plans.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10. Table: 'users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this table looks like without modification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>username</th>\n",
       "      <th>password</th>\n",
       "      <th>email</th>\n",
       "      <th>rank</th>\n",
       "      <th>membership</th>\n",
       "      <th>expire</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>ashes</td>\n",
       "      <td>71d4084be7fb37abb17491310ced29a029b806a1</td>\n",
       "      <td>abased.dns@abaseddns.com</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1397993224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>HansKlos</td>\n",
       "      <td>9497b6b88ce82360d3277c9057f4482a06f1e10e</td>\n",
       "      <td>kolo25197@wp.pl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Abased</td>\n",
       "      <td>12bf10a1269d352b803f16d305cf58393bd954cd</td>\n",
       "      <td>abased@live.com</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1768906710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146</td>\n",
       "      <td>webt89</td>\n",
       "      <td>a456453fd349dae2f1754b12b11dd4131ac00dfa</td>\n",
       "      <td>webt89@comcast.net</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>Stufflikedat</td>\n",
       "      <td>d7d5ae291a2d3cd588e6dd4e882cb3b4e9bbb015</td>\n",
       "      <td>tclubhd@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1393088350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68</td>\n",
       "      <td>Protection</td>\n",
       "      <td>b7b6d19bdc197aa0ba0cb2482b46dcab8a6f16bf</td>\n",
       "      <td>dffdf@sdds.nl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>tntwolve</td>\n",
       "      <td>f5ce60f9b50290be6498ac82dfb316139105d33a</td>\n",
       "      <td>cccamhd.net@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>mj4wz</td>\n",
       "      <td>5dd03b3779368a58269974ae7dd838d7f662f2a3</td>\n",
       "      <td>ankas@hotmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71</td>\n",
       "      <td>Unwrote</td>\n",
       "      <td>aaaa5279d74cf3f78c4c3b0a1622263e71907fa4</td>\n",
       "      <td>Africannn@outlook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>IRunShit</td>\n",
       "      <td>260a8444fc7acf29775a1fc6a396fae504f45094</td>\n",
       "      <td>blumaarts@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID      username                                  password  \\\n",
       "0   65         ashes  71d4084be7fb37abb17491310ced29a029b806a1   \n",
       "1  134      HansKlos  9497b6b88ce82360d3277c9057f4482a06f1e10e   \n",
       "2    1        Abased  12bf10a1269d352b803f16d305cf58393bd954cd   \n",
       "3  146        webt89  a456453fd349dae2f1754b12b11dd4131ac00dfa   \n",
       "4   67  Stufflikedat  d7d5ae291a2d3cd588e6dd4e882cb3b4e9bbb015   \n",
       "5   68    Protection  b7b6d19bdc197aa0ba0cb2482b46dcab8a6f16bf   \n",
       "6   69      tntwolve  f5ce60f9b50290be6498ac82dfb316139105d33a   \n",
       "7   70         mj4wz  5dd03b3779368a58269974ae7dd838d7f662f2a3   \n",
       "8   71       Unwrote  aaaa5279d74cf3f78c4c3b0a1622263e71907fa4   \n",
       "9   72      IRunShit  260a8444fc7acf29775a1fc6a396fae504f45094   \n",
       "\n",
       "                      email  rank  membership      expire  status  \n",
       "0  abased.dns@abaseddns.com     0          16  1397993224       0  \n",
       "1           kolo25197@wp.pl     0           0           0       0  \n",
       "2           abased@live.com     2          24  1768906710       0  \n",
       "3        webt89@comcast.net     0           0           0       0  \n",
       "4         tclubhd@gmail.com     0           3  1393088350       0  \n",
       "5             dffdf@sdds.nl     0           0           0       0  \n",
       "6     cccamhd.net@gmail.com     0           0           0       0  \n",
       "7         ankas@hotmail.com     0           0           0       0  \n",
       "8     Africannn@outlook.com     0           0           0       0  \n",
       "9       blumaarts@gmail.com     0           0           0       0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablename='users'\n",
    "\n",
    "pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Is this table different from other previous loaded table? YES \n",
    "#### Q2: Is this table similar to any table in the generic Booter database schema? YES \n",
    "    - This table looks like: users\n",
    "#### Q3: Are there modifications required? \n",
    "    - On the table name: \n",
    "        o \n",
    "    - On the column type: \n",
    "        o expire -> timestamp2datetime()\n",
    "    - On the column name:\n",
    "        o ID -> userid\n",
    "        o email -> useremail \n",
    "        o membership -> planid\n",
    "    - Add required columns:\n",
    "        o \n",
    "    - Split columns:\n",
    "        o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying table: 'users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>password</th>\n",
       "      <th>useremail</th>\n",
       "      <th>rank</th>\n",
       "      <th>planid</th>\n",
       "      <th>expire</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>ashes</td>\n",
       "      <td>71d4084be7fb37abb17491310ced29a029b806a1</td>\n",
       "      <td>abased.dns@abaseddns.com</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2014-04-20 11:27:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>HansKlos</td>\n",
       "      <td>9497b6b88ce82360d3277c9057f4482a06f1e10e</td>\n",
       "      <td>kolo25197@wp.pl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Abased</td>\n",
       "      <td>12bf10a1269d352b803f16d305cf58393bd954cd</td>\n",
       "      <td>abased@live.com</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2026-01-20 10:58:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146</td>\n",
       "      <td>webt89</td>\n",
       "      <td>a456453fd349dae2f1754b12b11dd4131ac00dfa</td>\n",
       "      <td>webt89@comcast.net</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>Stufflikedat</td>\n",
       "      <td>d7d5ae291a2d3cd588e6dd4e882cb3b4e9bbb015</td>\n",
       "      <td>tclubhd@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-02-22 16:59:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68</td>\n",
       "      <td>Protection</td>\n",
       "      <td>b7b6d19bdc197aa0ba0cb2482b46dcab8a6f16bf</td>\n",
       "      <td>dffdf@sdds.nl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>tntwolve</td>\n",
       "      <td>f5ce60f9b50290be6498ac82dfb316139105d33a</td>\n",
       "      <td>cccamhd.net@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>mj4wz</td>\n",
       "      <td>5dd03b3779368a58269974ae7dd838d7f662f2a3</td>\n",
       "      <td>ankas@hotmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71</td>\n",
       "      <td>Unwrote</td>\n",
       "      <td>aaaa5279d74cf3f78c4c3b0a1622263e71907fa4</td>\n",
       "      <td>Africannn@outlook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>IRunShit</td>\n",
       "      <td>260a8444fc7acf29775a1fc6a396fae504f45094</td>\n",
       "      <td>blumaarts@gmail.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid      username                                  password  \\\n",
       "0      65         ashes  71d4084be7fb37abb17491310ced29a029b806a1   \n",
       "1     134      HansKlos  9497b6b88ce82360d3277c9057f4482a06f1e10e   \n",
       "2       1        Abased  12bf10a1269d352b803f16d305cf58393bd954cd   \n",
       "3     146        webt89  a456453fd349dae2f1754b12b11dd4131ac00dfa   \n",
       "4      67  Stufflikedat  d7d5ae291a2d3cd588e6dd4e882cb3b4e9bbb015   \n",
       "5      68    Protection  b7b6d19bdc197aa0ba0cb2482b46dcab8a6f16bf   \n",
       "6      69      tntwolve  f5ce60f9b50290be6498ac82dfb316139105d33a   \n",
       "7      70         mj4wz  5dd03b3779368a58269974ae7dd838d7f662f2a3   \n",
       "8      71       Unwrote  aaaa5279d74cf3f78c4c3b0a1622263e71907fa4   \n",
       "9      72      IRunShit  260a8444fc7acf29775a1fc6a396fae504f45094   \n",
       "\n",
       "                  useremail  rank  planid              expire  status  \n",
       "0  abased.dns@abaseddns.com     0      16 2014-04-20 11:27:04       0  \n",
       "1           kolo25197@wp.pl     0       0 1970-01-01 00:00:00       0  \n",
       "2           abased@live.com     2      24 2026-01-20 10:58:30       0  \n",
       "3        webt89@comcast.net     0       0 1970-01-01 00:00:00       0  \n",
       "4         tclubhd@gmail.com     0       3 2014-02-22 16:59:10       0  \n",
       "5             dffdf@sdds.nl     0       0 1970-01-01 00:00:00       0  \n",
       "6     cccamhd.net@gmail.com     0       0 1970-01-01 00:00:00       0  \n",
       "7         ankas@hotmail.com     0       0 1970-01-01 00:00:00       0  \n",
       "8     Africannn@outlook.com     0       0 1970-01-01 00:00:00       0  \n",
       "9       blumaarts@gmail.com     0       0 1970-01-01 00:00:00       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the correct table name\n",
    "df_users = pd.read_csv(read_inserted_table(dumpfile, tablename),delimiter=\",\",error_bad_lines=False)\n",
    "\n",
    "# Converting columns\n",
    "df_users['expire'] = timestamp2datetime(df_users['expire']) \n",
    "\n",
    "# Changing names of columns\n",
    "df_users.rename(inplace=True, columns = {'ID':'userid',\n",
    "                                           'email':'useremail',\n",
    "                                           'membership': 'planid'})\n",
    "\n",
    "# Creating empty columns (with \"\" [for future string] or np.nan [for future float])\n",
    "\n",
    "# Showing some lines after adapt the table\n",
    "df_users.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>======================================================================\n",
    "<br>Final step of the manual part\n",
    "======================================================================</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Adding missing tables accordingly to our generic Booter database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_attacks= pd.DataFrame(columns=['id','userid','username','targetip','targeturl','duration','port','type','date'])\n",
    "#df_blacklist=pd.DataFrame(columns=['id','ip','note'])\n",
    "#df_friendsenemies=pd.DataFrame(columns=['id','ip','note','userid','type'])\n",
    "#df_gateways=pd.DataFrame(columns=['email'])\n",
    "#df_logins=pd.DataFrame(columns=['id','userid','username','userip','date'])\n",
    "#df_payments=pd.DataFrame(columns=['id','userid','username','amountpaid','paymentemail','planid','tid','date'])\n",
    "df_plans=pd.DataFrame(columns=['planid','planname','plandescr','price','maxboottime','concurrency'])\n",
    "df_servers=pd.DataFrame(columns=['id','ip'])\n",
    "df_settings=pd.DataFrame(columns=['url','sitename','siteemail'])\n",
    "#df_users=pd.DataFrame(columns=['userid','username','useremail','password','expire','plan'])      \n",
    "df_webshells=pd.DataFrame(columns=['id','url','status','lastchecked','attacktype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<br>\n",
    "STEP 2: Data Enrichment<br>\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Depending of the size of the data, this part can take HOURS. I tested for both small and big datasets and it worked. Be pacient. This will pay-off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Libraries needed to retrieve information from external databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cfscrape\n",
    "from lxml import etree\n",
    "import os.path\n",
    "import random\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Function to enrich IP addresseswith AS information and country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THANKS TO: team-cymru.org\n",
    "def iptoasn(iplist_teamcymruformat_filelocation,outputfile):\n",
    "    cat = subprocess.Popen(['cat', iplist_teamcymruformat_filelocation], \n",
    "                            stdout=subprocess.PIPE)\n",
    "    \n",
    "    netcat = subprocess.Popen(['netcat', 'whois.cymru.com', '43'],\n",
    "                              stdin=cat.stdout,\n",
    "                              stdout=outputfile)\n",
    "    time.sleep(3) #for some reason the poll does not work! This was the way to overcome the waiting time.\n",
    "    \n",
    "    return netcat.stdout      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Function to check if an IP address was Tor node in a given moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THANKS TO: exonerator.torproject.org\n",
    "def WasTorNode(ip, date ):\n",
    "    url=\"https://exonerator.torproject.org/?ip=\"+ip+\"&timestamp=\"+date\n",
    "    scraper = cfscrape.create_scraper()\n",
    "    scraped_html=scraper.get(url).content    \n",
    "    html_tree = etree.HTML(scraped_html)\n",
    "    result=html_tree.xpath(\"//h3[@class='panel-title']/text()\") # I was looking for <h3 class=\"panel-title\">Result is positive</h3>\n",
    "    tor_node=True if result == ['Result is positive'] else False\n",
    "    return tor_node \n",
    "# 'date' MUST BE formated as: Year-month-day (2016-03-31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Discovering the middle date of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    try:\n",
    "        middle_date=(min(df_attacks['date'])+((max(df_attacks['date'])-min(df_attacks['date']))/2))\n",
    "        raise\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        middle_date=(min(df_logins['date'])+((max(df_logins['date'])-min(df_logins['date']))/2))\n",
    "        raise\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        middle_date=(min(df_payments['date'])+((max(df_payments['date'])-min(df_payments['date']))/2))\n",
    "        raise\n",
    "    except:\n",
    "        pass\n",
    "except Exception:\n",
    "    print(\"There is no date in the entire dataset\")\n",
    "\n",
    "date_tor_check = middle_date.strftime('%Y-%m-%d')\n",
    "date_iptoasn_lookup= str(middle_date)\n",
    "print(date_tor_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Preparing to Perform IP to ASN info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_logins['middledate']=date_iptoasn_lookup\n",
    "df_attacks['middledate']=date_iptoasn_lookup\n",
    "df_friendsenemies['middledate']=date_iptoasn_lookup\n",
    "df_blacklist['middledate']=date_iptoasn_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1  Lookup IP to ASN info of table: logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/logins_iptoasn_out')== False):\n",
    "    logins_iptoasn_in = open('enrichments/logins_iptoasn_in', 'w+')\n",
    "    logins_iptoasn_in.write('begin\\nverbose\\n')\n",
    "    df_logins[['userip','middledate']].drop_duplicates().to_csv(logins_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "    logins_iptoasn_in.write('end')\n",
    "    logins_iptoasn_in.close()\n",
    "\n",
    "    logins_iptoasn_out = open('logins_iptoasn_out', 'w+')\n",
    "    iptoasn('logins_iptoasn_in',logins_iptoasn_out)\n",
    "    logins_iptoasn_out.close()\n",
    "else:\n",
    "    print(\"You already performed the lookup for this table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_logins_iptoasn = pd.read_csv('enrichments/logins_iptoasn_out',\\\n",
    "                                skiprows=1,\\\n",
    "                             delimiter=\"\\s+\\|\\s\",\\\n",
    "                             names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])\n",
    "\n",
    "df_logins_extended= pd.merge(df_logins,\n",
    "                              df_logins_iptoasn,\n",
    "                              how = 'left',\n",
    "                              left_on = 'userip',\n",
    "                              right_on = 'ip')\n",
    "\n",
    "# Changing name of columns to avoid misunderstandings\n",
    "df_logins_extended.rename(columns={'asn':'srcasn', \n",
    "                                   'ip':'srcip', \n",
    "                                   'bgp_prefix':'srcbgp_prefix', \n",
    "                                   'country':'srccountry' ,\n",
    "                                   'registry':'srcregistry',\n",
    "                                   'info_date':'srcinfo_date',\n",
    "                                   'info_request':'srcinfo_request'},\n",
    "                         inplace=True)\n",
    "\n",
    "\n",
    "df_logins_extended.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2  Lookup IP to ASN info of table: attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/attacks_iptoasn_out')== False):\n",
    "    attacks_iptoasn_in = open('enrichments/attacks_iptoasn_in', 'w+')\n",
    "    attacks_iptoasn_in.write('begin\\nverbose\\n')\n",
    "    df_attacks[['targetip','middledate']].drop_duplicates().to_csv(attacks_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "    attacks_iptoasn_in.write('end')\n",
    "    attacks_iptoasn_in.close()\n",
    "\n",
    "    attacks_iptoasn_out = open('attacks_iptoasn_out', 'w+')\n",
    "    iptoasn('attacks_iptoasn_in',attacks_iptoasn_out)\n",
    "    attacks_iptoasn_out.close()\n",
    "else:\n",
    "    print(\"You already performed the lookup for this table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_attacks_iptoasn = pd.read_csv('enrichments/attacks_iptoasn_out',\\\n",
    "                                skiprows=1,\\\n",
    "                             delimiter=\"\\s+\\|\\s\",\\\n",
    "                             names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])\n",
    "\n",
    "# Merging the iptoasn with the queried column\n",
    "df_attacks_extended= pd.merge(df_attacks,\n",
    "                              df_attacks_iptoasn,\n",
    "                              how = 'left',\n",
    "                              left_on = 'targetip',\n",
    "                              right_on = 'ip')\n",
    "\n",
    "# Changing name of columns to avoid misunderstandings\n",
    "df_attacks_extended.rename(columns={'asn':'targetasn', \n",
    "                                   'ip_y':'targetip', \n",
    "                                   'bgp_prefix':'targetbgp_prefix', \n",
    "                                   'country_y':'targetcountry' ,\n",
    "                                   'registry':'targetregistry',\n",
    "                                   'info_date':'targetinfo_date',\n",
    "                                   'info_request':'targetinfo_request'},\n",
    "                         inplace=True)\n",
    "df_attacks_extended.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3  Lookup IP to ASN info of table: friendsenemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/friendsenemies_iptoasn_out')== False):\n",
    "    friendsenemies_iptoasn_in = open('enrichments/friendsenemies_iptoasn_in', 'w+')\n",
    "    friendsenemies_iptoasn_in.write('begin\\nverbose\\n')\n",
    "    df_friendsenemies[['ip','middledate']].drop_duplicates().to_csv(friendsenemies_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "    friendsenemies_iptoasn_in.write('end')\n",
    "    friendsenemies_iptoasn_in.close()\n",
    "\n",
    "    friendsenemies_iptoasn_out = open('friendsenemies_iptoasn_out', 'w+')\n",
    "    iptoasn('friendsenemies_iptoasn_in',friendsenemies_iptoasn_out)\n",
    "    friendsenemies_iptoasn_out.close()\n",
    "else:\n",
    "    print(\"You already performed the lookup for this table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_friendsenemies_iptoasn = pd.read_csv('enrichments/friendsenemies_iptoasn_out',\\\n",
    "                                skiprows=1,\\\n",
    "                             delimiter=\"\\s+\\|\\s\",\\\n",
    "                             names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])\n",
    "\n",
    "# Merging the iptoasn with the queried column\n",
    "df_friendsenemies_extended= pd.merge(df_friendsenemies,\n",
    "                              df_friendsenemies_iptoasn,\n",
    "                              how = 'left',\n",
    "                              left_on = 'ip',\n",
    "                              right_on = 'ip')\n",
    "\n",
    "# Changing name of columns to avoid misunderstandings\n",
    "df_friendsenemies_extended.rename(columns={'asn':'friendsenemiesasn', \n",
    "                                   'ip':'friendsenemiesip', \n",
    "                                   'bgp_prefix':'friendsenemiesbgp_prefix', \n",
    "                                   'country':'friendsenemiescountry' ,\n",
    "                                   'registry':'friendsenemiesregistry',\n",
    "                                   'info_date':'friendsenemiesinfo_date',\n",
    "                                   'info_request':'friendsenemiesinfo_request',\n",
    "                                   'as_name': 'friendsenemiesas_name'},\n",
    "                         inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.4  Lookup IP to ASN info of table: blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/blacklist_iptoasn_out')== False):\n",
    "    blacklist_iptoasn_in = open('enrichments/blacklist_iptoasn_in', 'w+')\n",
    "    blacklist_iptoasn_in.write('begin\\nverbose\\n')\n",
    "    df_blacklist[['ip','middledate']].drop_duplicates().to_csv(blacklist_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "    blacklist_iptoasn_in.write('end')\n",
    "    blacklist_iptoasn_in.close()\n",
    "\n",
    "    blacklist_iptoasn_out = open('blacklist_iptoasn_out', 'w+')\n",
    "    iptoasn('blacklist_iptoasn_in',blacklist_iptoasn_out)\n",
    "    blacklist_iptoasn_out.close()\n",
    "else:\n",
    "    print(\"You already performed the lookup for this table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_blacklist_iptoasn = pd.read_csv('enrichments/blacklist_iptoasn_out',\\\n",
    "                                skiprows=1,\\\n",
    "                             delimiter=\"\\s+\\|\\s\",\\\n",
    "                             names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])\n",
    "\n",
    "# Merging the iptoasn with the queried column\n",
    "df_blacklist_extended= pd.merge(df_blacklist,\n",
    "                              df_blacklist_iptoasn,\n",
    "                              how = 'left',\n",
    "                              left_on = 'ip',\n",
    "                              right_on = 'ip')\n",
    "\n",
    "# Changing name of columns to avoid misunderstandings\n",
    "df_blacklist_extended.rename(columns={'asn':'blacklistasn', \n",
    "                                   'ip':'blacklistip', \n",
    "                                   'bgp_prefix':'blacklistbgp_prefix', \n",
    "                                   'country':'blacklistcountry' ,\n",
    "                                   'registry':'blacklistregistry',\n",
    "                                   'info_date':'blacklistinfo_date',\n",
    "                                   'info_request':'blacklistinfo_request',\n",
    "                                   'as_name': 'blacklistas_name'},\n",
    "                         inplace=True)\n",
    "df_blacklist_extended.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1. Check if IP was a TOR node for table: login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_tor_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(df_logins['userip'].unique())<1200:\n",
    "    if (os.path.exists('enrichments/logins_torcheck')== False):\n",
    "        print(\"Note: it can take a while to finish...\")\n",
    "        logins_torcheck = open('logins_torcheck', 'w+')\n",
    "        for i in df_logins['userip'].unique():\n",
    "            wasTor=WasTorNode(i,date_tor_check)\n",
    "            print(i, wasTor, file=logins_torcheck)\n",
    "    #         print(i, wasTor) #DEBUGING =D\n",
    "            time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "            logins_torcheck.flush()\n",
    "\n",
    "        logins_torcheck.close()\n",
    "    else:\n",
    "        print(\"The IP addresses from this table were already checked.\")\n",
    "else:\n",
    "        print(\"Aborted!!! It will take more than one hour to analyse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_logins_torcheck = pd.read_csv('enrichments/logins_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['userip', 'tor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2. Check if IP was a TOR node for table: attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(df_attacks['targetip'].unique())<1200:\n",
    "    if (os.path.exists('enrichments/attacks_torcheck')== False):\n",
    "        print(\"Note: it can take a while to finish...\",len(df_attacks['targetip'].unique())*3,\"seconds (in the worst case).\")\n",
    "\n",
    "        attacks_torcheck = open('attacks_torcheck', 'w+')\n",
    "\n",
    "        for i in df_attacks['targetip'].unique():\n",
    "            wasTor=WasTorNode(i,date_tor_check)\n",
    "            print(i, wasTor, file=attacks_torcheck)\n",
    "            print(i, wasTor) #DEBUGING =D\n",
    "            time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "            attacks_torcheck.flush()\n",
    "\n",
    "        attacks_torcheck.close()\n",
    "    else:\n",
    "        print(\"The IP addresses from this table were already checked.\") \n",
    "else:\n",
    "        print(\"Aborted!!! It will take more than one hour to analyse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_attacks_torcheck = pd.read_csv('enrichments/attacks_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['targetip', 'tor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3. Check if IP was a TOR node for table: friendsenemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_friendsenemies['ip'].unique()) <1200:\n",
    "    if (os.path.exists('enrichments/friendsenemies_torcheck')== False):\n",
    "        print(\"Note: it can take a while to finish...\",len(df_friendsenemies['ip'].unique())*3,\"seconds (in the worst case).\")\n",
    "\n",
    "        friendsenemies_torcheck = open('enrichments/friendsenemies_torcheck', 'w+')\n",
    "\n",
    "        for i in df_friendsenemies['ip'].unique():\n",
    "            wasTor=WasTorNode(i,date_tor_check)\n",
    "            print(i, wasTor, file=friendsenemies_torcheck)\n",
    "        #     print(i, wasTor) #DEBUGING =D\n",
    "            time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "            friendsenemies_torcheck.flush()\n",
    "\n",
    "        friendsenemies_torcheck.close()\n",
    "    else:\n",
    "        print(\"The IP addresses from this table were already checked.\") \n",
    "else:\n",
    "        print(\"Aborted!!! It will take more than one hour to analyse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_friendsenemies_torcheck = pd.read_csv('enrichments/friendsenemies_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['ip', 'tor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4. Check if IP was a TOR node for table: blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_blacklist['ip'].unique()) < 1200:\n",
    "    if (os.path.exists('enrichments/blacklist_torcheck')== False):\n",
    "        print(\"Note: it can take a while to finish...\",len(df_blacklist['ip'].unique())*3,\"seconds (in the worst case).\")\n",
    "\n",
    "        blacklist_torcheck = open('enrichments/blacklist_torcheck', 'w+')\n",
    "\n",
    "        for i in df_blacklist['ip'].unique():\n",
    "            wasTor=WasTorNode(i,date_tor_check)\n",
    "            print(i, wasTor, file=blacklist_torcheck)\n",
    "    #         print(i, wasTor) #DEBUGING =D\n",
    "            time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "            blacklist_torcheck.flush()\n",
    "\n",
    "        blacklist_torcheck.close()\n",
    "    else:\n",
    "        print(\"The IP addresses from this table were already checked.\") \n",
    "else:\n",
    "        print(\"Aborted!!! It will take more than one hour to analyse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_blacklist_torcheck = pd.read_csv('enrichments/blacklist_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['ip', 'tor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Relation between Attack dates and Login dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearestDate(base_date, date_list):\n",
    "    nearest={}\n",
    "    for date in date_list:\n",
    "        if (base_date.timestamp() - date.timestamp())>=0:\n",
    "            nearest[base_date.timestamp() - date.timestamp()]= date\n",
    "    return nearest[min(nearest.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is the TOTAL number records to be checks!!!!\n",
    "len(df_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_attacks['nearestlogin']=\"\"\n",
    "df_attacks['nearestlogin']=pd.to_datetime(df_attacks['nearestlogin'])\n",
    "    \n",
    "if len(df_attacks)>0 and len(df_logins)>0:\n",
    "    #When was the last login of the user that performed attacks\n",
    "    df_attacks['nearestlogin']=\"\"\n",
    "    df_attacks['nearestlogin']=pd.to_datetime(df_attacks['nearestlogin'])\n",
    "\n",
    "    for index, row in df_attacks.head(100).iterrows():\n",
    "        intermediate_df= df_logins[df_logins['username']==row['username']]\n",
    "        nearestlogindate= nearestDate(row['date'],intermediate_df['date'])\n",
    "        df_attacks.set_value(index, 'nearestlogin', nearestlogindate)\n",
    "\n",
    "        #DEBUGGING\n",
    "        if index % 1000 == 0:\n",
    "            print(index,\": +1000 records analysed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_attacks['nearestlogin'].value_counts()) >1:\n",
    "    df_attacks_and_logins = pd.merge(df_attacks_extended,\n",
    "                                     df_logins_extended,\n",
    "                                     how = 'left',\n",
    "                                     left_on = ['username','nearestlogin'],\n",
    "                                     right_on = ['username','date'])\n",
    "else:\n",
    "    df_attacks_and_logins=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<br>\n",
    "STEP 3: Automatic Analysis\n",
    "<br>\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Libraries that I use to plot figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import *\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "plt.style.use('seaborn-muted')\n",
    "# plt.rcParams['font.family'] = 'serif'\n",
    "# plt.rcParams['font.size'] = 12\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1. Number of records per table (part of the generic Booter database schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_users),len(df_logins),len(df_attacks),len(df_payments),len(df_settings),len(df_gateways), len(df_friendsenemies),len(df_blacklist),len(df_webshells),len(df_servers),len(df_plans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2. Number of users, customers, attackers, and their intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(set(df_users['userid'].unique())) > 1:\n",
    "    users_set=set(df_users['userid'].unique())\n",
    "else:\n",
    "    users_set=set(df_users['username'].unique())\n",
    "    \n",
    "if len(set(df_logins['userid'].unique())) > 1:\n",
    "    userslogin_set=set(df_logins['userid'].unique())\n",
    "else:\n",
    "    userslogin_set=set(df_logins['username'].unique())\n",
    "\n",
    "if len(set(df_payments['userid'].unique())) > 1:\n",
    "    customers_set=set(df_payments['userid'].unique())\n",
    "else:\n",
    "    customers_set=set(df_payments['username'].unique())\n",
    "\n",
    "if len(set(df_attacks['userid'].unique())) > 1:\n",
    "    attackers_set=set(df_attacks['userid'].unique())\n",
    "else:\n",
    "    attackers_set=set(df_attacks['username'].unique())\n",
    "\n",
    "intersec_customers_attacker=pd.Series(list(customers_set.intersection(attackers_set)))\n",
    "intersec_users_customers=pd.Series(list(users_set.intersection(customers_set)))\n",
    "intersec_users_attackers=pd.Series(list(users_set.intersection(attackers_set)))\n",
    "intersec_users_customers_attackers=pd.Series(list(users_set.intersection(customers_set).intersection(attackers_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(users_set),len(userslogin_set),len(customers_set),len(attackers_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,3))\n",
    "fig.suptitle('Users, Customers & Attackers', fontsize=14)\n",
    "\n",
    "ax = plt.subplot2grid((1,1), (0,0))\n",
    "\n",
    "venn=venn3(ax=ax,subsets = {'001':len(attackers_set)-len(intersec_customers_attacker)-len(intersec_users_attackers)+len(intersec_users_customers_attackers), \n",
    "                            '010':len(customers_set)-len(intersec_users_customers)-len(intersec_customers_attacker)+len(intersec_users_customers_attackers), \n",
    "                            '011':len(intersec_customers_attacker)-len(intersec_users_customers_attackers),\n",
    "                            '100':len(users_set)-len(intersec_users_customers)-len(intersec_users_attackers)+len(intersec_users_customers_attackers),\n",
    "                            '101':len(intersec_users_attackers)-len(intersec_users_customers_attackers),\n",
    "                            '110':len(intersec_users_customers)-len(intersec_users_customers_attackers),\n",
    "                            '111':len(intersec_users_customers_attackers)},\\\n",
    "          set_labels = ('Users', 'Customers','Attackers'),\\\n",
    "          alpha=1)\n",
    "try:\n",
    "    venn.get_patch_by_id('100').set_color('#404096')\n",
    "except:\n",
    "    print(\"*Users set is empty!\")  \n",
    "    \n",
    "try:\n",
    "    venn.get_patch_by_id('110').set_color('#DEA73A')\n",
    "except:\n",
    "    print(\"*Customers set is empty!\")   \n",
    "\n",
    "try:\n",
    "    venn.get_patch_by_id('001').set_color('#D92120')\n",
    "except:\n",
    "    print(\"*Attackers set is empty!\")\n",
    "\n",
    "fig.show()\n",
    "# fig.savefig('../figs/timeseries_attacks.eps', format='eps', dpi=1200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3. Distribution of login times per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_logins['userid'].value_counts()) > 0:\n",
    "    num_distinct_logins_per_user=df_logins['userid'].value_counts()\n",
    "else:\n",
    "    num_distinct_logins_per_user=df_logins['username'].value_counts()\n",
    "\n",
    "freq_distinct_logins_per_user=num_distinct_logins_per_user.value_counts()\n",
    "cum_dist_user_logins = np.linspace(0.,1.,len(num_distinct_logins_per_user))\n",
    "cdf_user_logins = pd.Series(cum_dist_user_logins, index=num_distinct_logins_per_user.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(num_distinct_logins_per_user)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Distribution of Login Times by Users:', fontsize=14, y=1.05,x=0.35)\n",
    "    \n",
    "    #Plot CDF\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    ax1 = cdf_user_logins.plot(ax=ax1,lw=2, drawstyle='steps',legend=False)\n",
    "    ax1.set_xlabel(\"# logins\")\n",
    "    ax1.set_ylabel(\"CDF of Users\")\n",
    "    ax1.set_ylim(0,1.05)\n",
    "    ax1.set_title(\"\")\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    \n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    freq_distinct_logins_per_user.plot(ax=ax2,kind='pie', \n",
    "                                       labels=None, \n",
    "                                       legend=False,\n",
    "                                       startangle=270,\n",
    "#                                        colors=sns.color_palette()\n",
    "                                       )\n",
    "    ax2.set_ylabel(\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*freq_distinct_logins_per_user.values)/(freq_distinct_logins_per_user.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(freq_distinct_logins_per_user.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.5, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/login_times.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Number of Users that Login via TOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_logins_torcheck[df_logins_torcheck['tor']==True]['userip'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Number of Distinct IP addresses by Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_logins.groupby(['userid','userip']).size().reset_index()['userid'].value_counts()) >0:\n",
    "    num_distinct_ips_per_user=df_logins.groupby(['userid','userip']).size().reset_index()['userid'].value_counts()\n",
    "else:\n",
    "    num_distinct_ips_per_user=df_logins.groupby(['username','userip']).size().reset_index()['username'].value_counts()\n",
    "    \n",
    "freq_distinct_ips_per_user=num_distinct_ips_per_user.value_counts()\n",
    "cum_dist_user_ips = np.linspace(0.,1.,len(num_distinct_ips_per_user))\n",
    "cdf_user_ips = pd.Series(cum_dist_user_ips, index=num_distinct_ips_per_user.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(num_distinct_ips_per_user)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Distribution of Distinct IP address used by Users:', fontsize=14, y=1.05, x=0.4)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    ax1 = cdf_user_ips.plot( ax=ax1,lw=2, drawstyle='steps',legend=False)\n",
    "    ax1.set_xlabel(\"# IPs\")\n",
    "    ax1.set_ylabel(\"CDF of Users\")\n",
    "    ax1.set_ylim(0,1.05)\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    freq_distinct_ips_per_user.plot(ax=ax2,kind='pie',\n",
    "                                    labels=None,legend=False,\n",
    "                                       startangle=270,\n",
    "#                                        colors=sns.color_palette()\n",
    "                                       )\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*freq_distinct_ips_per_user.values)/(freq_distinct_ips_per_user.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(freq_distinct_ips_per_user.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.5, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/num_ips_by_users.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Number of Payments by Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_payments['userid'].value_counts())>0:\n",
    "    num_distinct_payments_per_user=df_payments['userid'].value_counts()\n",
    "else:\n",
    "    num_distinct_payments_per_user=df_payments['username'].value_counts()\n",
    "\n",
    "freq_distinct_payments_per_user=num_distinct_payments_per_user.value_counts()\n",
    "cum_dist_user_payments = np.linspace(0.,1.,len(num_distinct_payments_per_user))\n",
    "cdf_user_payments = pd.Series(cum_dist_user_payments, index=num_distinct_payments_per_user.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(num_distinct_payments_per_user)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Distribution of Number of Payments by Users:', fontsize=14, y=1.05, x=0.4)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    ax1 = cdf_user_payments.plot( ax=ax1,lw=2, drawstyle='steps',legend=False)\n",
    "    ax1.set_xlabel(\"# Payment\")\n",
    "    ax1.set_ylabel(\"CDF of Users\")\n",
    "    ax1.set_ylim(0,1.05)\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    freq_distinct_payments_per_user.plot(ax=ax2,kind='pie', \n",
    "                                         labels=None,legend=False,\n",
    "                                         startangle=270)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*freq_distinct_payments_per_user.values)/(freq_distinct_payments_per_user.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(freq_distinct_payments_per_user.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.55, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/payments_distribution.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Total Amount of Money Earned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_payments['amountpaid']) >0:\n",
    "    total_earned=df_payments['amountpaid'].values.sum()\n",
    "    'US$ {:,.2f}'.format(float(total_earned))\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. Amount of Money Paid by Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_distinct_payments_money_per_user=df_payments['amountpaid'].value_counts()\n",
    "freq_distinct_payments_money_per_user=num_distinct_payments_money_per_user.value_counts()\n",
    "cum_dist_user_payments_money = np.linspace(0.,1.,len(num_distinct_payments_money_per_user))\n",
    "cdf_user_payments_money = pd.Series(cum_dist_user_payments_money, index=num_distinct_payments_money_per_user.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(num_distinct_payments_money_per_user)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Distribution of Money Payments by Users:', fontsize=14, y=1.05, x=0.4)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    ax1 = cdf_user_payments_money.plot( ax=ax1,lw=2, drawstyle='steps',legend=False)\n",
    "    ax1.set_xlabel(\"$\")\n",
    "    ax1.set_ylabel(\"CDF of Users\")\n",
    "    ax1.set_ylim(0,1.05)\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    freq_distinct_payments_money_per_user.plot(ax=ax2,kind='pie', \n",
    "                                               labels=None,legend=False,\n",
    "                                               startangle=270)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*freq_distinct_payments_money_per_user.values)/(freq_distinct_payments_money_per_user.values.sum())\n",
    "    labels = ['${0:1.2f} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(freq_distinct_payments_money_per_user.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.6, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/distribution_amount_paid.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.8. Countries from where Users Access Booters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logins_country_distribution_sorted = df_logins_iptoasn['country'].value_counts(sort=True,ascending=True)\n",
    "logins_country_distribution = df_logins_iptoasn['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(logins_country_distribution)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Users Accessing from Countries:', fontsize=14, y=1.05, x=0.28)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    logins_country_distribution_sorted.plot(ax=ax1,kind='barh')\n",
    "    ax1.set_ylabel(\"# access\")\n",
    "    ax1.set_xlabel(\"Country\")\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    logins_country_distribution.plot(ax=ax2,kind='pie', \n",
    "                                     labels=None,legend=False,\n",
    "                                     startangle=270)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*logins_country_distribution.values)/(logins_country_distribution.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(logins_country_distribution.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.55, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/user_countries.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9. Countries of Blacklisted IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklist_country_distribution=df_blacklist_iptoasn['country'].value_counts()\n",
    "blacklist_country_distribution_sorted=df_blacklist_iptoasn['country'].value_counts(sort=True,ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(blacklist_country_distribution)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Countries of blacklisted IPs', fontsize=14, y=1.05, x=0.28)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    blacklist_country_distribution_sorted.plot(ax=ax1,kind='barh')\n",
    "    ax1.set_ylabel(\"# Access\")\n",
    "    ax1.set_xlabel(\"Country\")\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    blacklist_country_distribution.plot(ax=ax2,kind='pie', \n",
    "                                        labels=None,legend=False,\n",
    "                                        startangle=270)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*blacklist_country_distribution.values)/(logins_country_distribution.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(blacklist_country_distribution.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.55, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/blacklist_countries.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10. Countries of Target IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attacks_country_distribution=df_attacks_iptoasn['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(attacks_country_distribution)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Countries of target IPs', fontsize=14, y=1.05, x=0.28)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    attacks_country_distribution.plot(ax=ax1,kind='bar')\n",
    "    ax1.set_ylabel(\"# Access\")\n",
    "    ax1.set_xlabel(\"Country\")\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    attacks_country_distribution.plot(ax=ax2,kind='pie', \n",
    "                                      labels=None,legend=False,\n",
    "                                      startangle=270)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*attacks_country_distribution.values)/(attacks_country_distribution.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(attacks_country_distribution.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.55, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig('figs/attack_countries_distribution.eps',bbox_inches='tight', format='eps', dpi=1200) \n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.12. Attacks on Same Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_attacks_on_sametarget=df_attacks['targetip'].value_counts()\n",
    "\n",
    "freq_num_attacks_on_sametarget=num_attacks_on_sametarget.value_counts()\n",
    "cum_num_attacks_on_sametarget = np.linspace(0.,1.,len(num_attacks_on_sametarget))\n",
    "cdf_num_attacks_on_sametarget = pd.Series(cum_num_attacks_on_sametarget, index=num_attacks_on_sametarget.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(num_attacks_on_sametarget)>0:\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.suptitle('* Attacks on Same Targets:', fontsize=14, y=1.05,x=0.28)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,2), (0,0))\n",
    "    ax1 = cdf_num_attacks_on_sametarget.plot( ax=ax1,lw=2, drawstyle='steps',legend=False)\n",
    "    ax1.set_xlabel(\"# IPs\")\n",
    "    ax1.set_ylabel(\"CDF of Users\")\n",
    "    ax1.set_ylim(0,1.05)\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    ax2 = plt.subplot2grid((1,2), (0,1))\n",
    "    freq_num_attacks_on_sametarget.plot(ax=ax2,kind='pie',\n",
    "                                        labels=None,legend=False,\n",
    "                                        startangle=270)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ####\n",
    "    # For Pie Chart Better Legend box\n",
    "    porcent = (100.*freq_num_attacks_on_sametarget.values)/(freq_num_attacks_on_sametarget.values.sum())\n",
    "    labels = ['{0} - {1:1.2f} %'.\\\n",
    "              format(i,j) for i,j in zip(freq_num_attacks_on_sametarget.index, porcent)]\n",
    "    # To Sort Legend (defaulf: keeps the same order)\n",
    "#     patches, labels, dummy =  zip(*sorted(zip(patches, labels, freq_distinct_logins_per_user.values),\n",
    "#                                           key=lambda x: x[2],\n",
    "#                                           reverse=True))\n",
    "    legend_show_top=10\n",
    "    ax2.legend(ax2.patches[0:legend_show_top], \n",
    "               labels[0:legend_show_top], \n",
    "               bbox_to_anchor=(1.55, 1.),\n",
    "               fontsize=10)\n",
    "    ####\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.show()\n",
    "    fig.savefig('figs/attacks_on_same_target.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11. Attacks per day (timeseries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_attacks)>0:\n",
    "    attack_timeseries=df_attacks.set_index(['date']).groupby(pd.TimeGrouper(freq='D')).agg(['count'])['action']\n",
    "    attack_mean_perday=attack_timeseries.mean()\n",
    "    attack_median_perday=attack_timeseries.median()\n",
    "else:\n",
    "    attack_timeseries=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(attack_timeseries)>0:\n",
    "    fig = plt.figure(figsize=(6,3))\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,1), (0,0), rowspan=2)\n",
    "    attack_timeseries.plot(ax=ax1,\n",
    "                           lw=2,\n",
    "                           legend=False,\n",
    "    #                        style='--'\n",
    "                          )\n",
    "\n",
    "    # X and Y Labels and Ticks\n",
    "    ax1.set_xlabel(\"Time (bin=day)\")\n",
    "    ax1.set_ylabel(\"# Attacks\")\n",
    "\n",
    "    ax1.annotate(str(int(attack_median_perday[0]))+' (median)', \n",
    "                 (min(df_attacks['date']), attack_median_perday),\n",
    "                 xytext=(350, -1), \n",
    "                 textcoords='offset points',\n",
    "                 color='black', \n",
    "                 arrowprops=dict(arrowstyle='-|>',\n",
    "                                 color='black'))\n",
    "    fig.savefig('figs/attacks_timeseries.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.12. Time Between Logins and Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_attacks_and_logins)>0:\n",
    "    print(\"redo\")\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.13. Who attack whom? (users on the country level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(df_attacks_extended)>0 and len(df_logins_extended)>0:\n",
    "    merged_attacks_logins = pd.merge(df_attacks_extended,\n",
    "                                  df_logins_extended,\n",
    "                                  how = 'left',\n",
    "                                  left_on = 'date',\n",
    "                                  right_on = 'date')[['targetcountry','srccountry']]\n",
    "\n",
    "    who_against_whom = merged_attacks_logins.groupby(['targetcountry','srccountry'])\\\n",
    "                            .size()\\\n",
    "                            .reset_index()\\\n",
    "                            .pivot('srccountry','targetcountry',0)\n",
    "else:\n",
    "    who_against_whom =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(who_against_whom)>0:\n",
    "    fig = plt.figure(figsize=(8,12))\n",
    "    fig.suptitle('Countries of Target IPs', fontsize=14, y=.92)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1,1), (0,0))\n",
    "    sns.set()\n",
    "    sns.heatmap(who_against_whom,\n",
    "                ax=ax1,\n",
    "#                 cmap=\"YlGnBu\",\n",
    "    #             linewidths=.5,\n",
    "    #             annot=True\n",
    "                )\n",
    "\n",
    "    ax1.set_ylabel(\"Source Country\")\n",
    "    ax1.set_xlabel(\"Attack Target Country\")\n",
    "\n",
    "    fig.show()\n",
    "    fig.savefig('figs/who_attack_whom.eps', bbox_inches='tight',format='eps', dpi=1200)\n",
    "else:\n",
    "    print(\"Unfortunately, there is no data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<br>\n",
    "FIFTH PART: Query Interface<br>\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact, Dropdown,HTML\n",
    "from IPython.display import display,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_by_userid_submit(sender):\n",
    "    clear_output()\n",
    "    print(\"Searching by id =\",search_by_userid.value)\n",
    "    \n",
    "    if len(df_users[df_users['userid']== int(search_by_userid.value)])>0:\n",
    "        display(df_users[df_logins['userid']== int(search_by_userid.value)])\n",
    "    \n",
    "    if len(df_logins_extended[df_logins_extended['userid']== int(search_by_userid.value)])>0:\n",
    "        display(df_logins_extended[df_logins_extended['userid']== int(search_by_userid.value)])\n",
    "    \n",
    "    if len(df_attacks_extended[df_attacks_extended['userid']== int(search_by_userid.value)])>0:\n",
    "        display(df_attacks_extended[df_attacks_extended['userid']== int(search_by_userid.value)])\n",
    "    \n",
    "    if len(df_payments[df_payments['userid']== int(search_by_userid.value)])>0:\n",
    "        display(df_payments[df_payments['userid']== int(search_by_userid.value)])\n",
    "\n",
    "def search_by_username_submit(sender):\n",
    "    clear_output()\n",
    "    print(\"Searching by username =\",search_by_username.value,\"\\n\")\n",
    "    \n",
    "    if len(df_users[df_users['username']== search_by_username.value])>0:\n",
    "        print(\"Table df_users:\")\n",
    "        display(df_users[df_users['username']== search_by_username.value])\n",
    "    \n",
    "    if len(df_logins_extended[df_logins_extended['username']== search_by_username.value])>0:\n",
    "        print(\"Table df_logins:\")\n",
    "        display(df_logins_extended[df_logins_extended['username']== search_by_username.value])\n",
    "\n",
    "    if len(df_attacks_extended[df_attacks_extended['username']== search_by_username.value])>0:\n",
    "        print(\"Table df_attacks:\")\n",
    "        display(df_attacks_extended[df_attacks_extended['username']== search_by_username.value])\n",
    "    \n",
    "    if len(df_payments[df_payments['username']== search_by_username.value])>0:\n",
    "        print(\"Table df_payments:\")\n",
    "        display(df_payments[df_payments['username']== search_by_username.value])\n",
    "        \n",
    "def search_by_ip_submit(sender):\n",
    "    clear_output()\n",
    "    print(\"Searching by IP address =\",str(search_by_ip.value),\"\\n\")\n",
    "    \n",
    "    if len(df_logins_extended[df_logins_extended['userip']== str(search_by_ip.value)])>0:\n",
    "        print(\"Table df_logins (as ATTACKER:\")\n",
    "        display(df_logins_extended[df_logins_extended['userip']== str(search_by_ip.value)])\n",
    "     \n",
    "    if len(df_attacks_extended[df_attacks_extended['targetip']== str(search_by_ip.value)])>0:\n",
    "        print(\"Table df_attacks (as TARGET):\")\n",
    "        display(df_attacks_extended[df_attacks_extended['targetip']== str(search_by_ip.value)])  \n",
    "      \n",
    "       \n",
    "def search_by_asn_submit(sender):\n",
    "    clear_output()\n",
    "    print(\"Searching by Autonomous System Number (ASN) =\",search_by_asn.value,\"\\n\")\n",
    "    \n",
    "    if len(df_logins_extended[df_logins_extended['srcasn']== int(search_by_asn.value)])>0:\n",
    "        print(\"Table df_logins (as ATTACKER):\")\n",
    "        display(df_logins_extended[df_logins_extended['srcasn']== int(search_by_asn.value)])\n",
    "    \n",
    "    if len(df_attacks_extended[df_attacks_extended['targetasn']== str(search_by_asn.value)])>0:\n",
    "        print(\"Table df_attacks (as TARGET):\")\n",
    "        display(df_attacks_extended[df_attacks_extended['targetasn']== str(search_by_asn.value)])\n",
    "\n",
    "    if len(df_attacks_extended[df_attacks_extended['targetasn']== str(search_by_asn.value)])>0:\n",
    "        print(\"Table df_attacks (as TARGET):\")\n",
    "        display(df_attacks_extended[df_attacks_extended['targetasn']== str(search_by_asn.value)])\n",
    "\n",
    "        \n",
    "country_list=pd.read_csv('https://raw.githubusercontent.com/datasets/country-list/master/data.csv',delimiter=\",\",error_bad_lines=False)\n",
    "def search_by_country_submit():\n",
    "    country_code=country_list[country_list['Name']==search_by_country.value]['Code'].values[0]\n",
    "    clear_output()\n",
    "    print(\"Searching by Country =\",search_by_country.value,\"\\n\")\n",
    "    \n",
    "    if len(df_logins_extended[df_logins_extended['srccountry']== country_code])>0:\n",
    "        print(\"Table df_logins (as ATTACKER):\")\n",
    "        display(df_logins_extended[df_logins_extended['srccountry']== country_code])\n",
    "    \n",
    "    if len(df_attacks_extended[df_attacks_extended['targetcountry']== country_code])>0:\n",
    "        print(\"Table df_attacks (as TARGET):\")\n",
    "        display(df_attacks_extended[df_attacks_extended['targetcountry']== country_code])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(HTML('<h3>*Search by (only) one field per time:</h3>'))\n",
    "\n",
    "search_by_username = widgets.Text(description=\"username\")\n",
    "display(search_by_username)\n",
    "search_by_username.on_submit(search_by_username_submit)\n",
    "\n",
    "search_by_userid = widgets.Text(description=\"userid\")\n",
    "display(search_by_userid)\n",
    "search_by_userid.on_submit(search_by_userid_submit)\n",
    "\n",
    "search_by_ip = widgets.Text(description=\"IP\")\n",
    "display(search_by_ip)\n",
    "search_by_ip.on_submit(search_by_ip_submit)\n",
    "\n",
    "search_by_asn = widgets.Text(description=\"ASN\")\n",
    "display(search_by_asn)\n",
    "search_by_asn.on_submit(search_by_asn_submit)\n",
    "\n",
    "search_by_country = Dropdown(description=\"Country\", options=country_list['Name'].tolist())\n",
    "search_by_country.on_trait_change(search_by_country_submit, name=\"value\")\n",
    "display(search_by_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
